{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "571652b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.sparse import hstack as sp_hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd46d3",
   "metadata": {},
   "source": [
    "### **Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a871de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = Path(\"../dataset_test.csv\")\n",
    "train_dir = Path(\"../dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0adbcb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8475"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(train_dir)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43ee1a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silent Hill</td>\n",
       "      <td>Horror, Mystery</td>\n",
       "      <td>Rose, a desperate mother takes her adopted dau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breaking the Waves</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>In a small and conservative Scottish village, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wind Chill</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>Two college students share a ride home for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Godmothered</td>\n",
       "      <td>Family, Fantasy, Comedy</td>\n",
       "      <td>A young and unskilled fairy godmother that ven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donkey Skin</td>\n",
       "      <td>Fantasy, Comedy, Music, Romance</td>\n",
       "      <td>A fairy godmother helps a princess disguise he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8470</th>\n",
       "      <td>Infested</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>Residents of a rundown French apartment buildi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>The Tailor of Panama</td>\n",
       "      <td>Drama, Thriller</td>\n",
       "      <td>A British spy is banished to Panama after havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8472</th>\n",
       "      <td>Bad Education</td>\n",
       "      <td>Drama, Crime</td>\n",
       "      <td>An examination on the effect of Franco-era rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>From Dusk Till Dawn</td>\n",
       "      <td>Horror, Action, Thriller, Crime</td>\n",
       "      <td>After kidnapping a father and his two kids, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>Road Trip</td>\n",
       "      <td>Comedy, Adventure</td>\n",
       "      <td>After an Ithaca College student films his one-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8475 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie_name                            genre  \\\n",
       "0              Silent Hill                  Horror, Mystery   \n",
       "1       Breaking the Waves                   Drama, Romance   \n",
       "2               Wind Chill          Drama, Horror, Thriller   \n",
       "3              Godmothered          Family, Fantasy, Comedy   \n",
       "4              Donkey Skin  Fantasy, Comedy, Music, Romance   \n",
       "...                    ...                              ...   \n",
       "8470              Infested                 Horror, Thriller   \n",
       "8471  The Tailor of Panama                  Drama, Thriller   \n",
       "8472         Bad Education                     Drama, Crime   \n",
       "8473   From Dusk Till Dawn  Horror, Action, Thriller, Crime   \n",
       "8474             Road Trip                Comedy, Adventure   \n",
       "\n",
       "                                            description  \n",
       "0     Rose, a desperate mother takes her adopted dau...  \n",
       "1     In a small and conservative Scottish village, ...  \n",
       "2     Two college students share a ride home for the...  \n",
       "3     A young and unskilled fairy godmother that ven...  \n",
       "4     A fairy godmother helps a princess disguise he...  \n",
       "...                                                 ...  \n",
       "8470  Residents of a rundown French apartment buildi...  \n",
       "8471  A British spy is banished to Panama after havi...  \n",
       "8472  An examination on the effect of Franco-era rel...  \n",
       "8473  After kidnapping a father and his two kids, th...  \n",
       "8474  After an Ithaca College student films his one-...  \n",
       "\n",
       "[8475 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5793b",
   "metadata": {},
   "source": [
    "## **Text to disperse vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f703f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"movie_name\"].fillna(\"\") + \" [SEP] \" + df[\"description\"].fillna(\"\")\n",
    "y_list = df[\"genre\"].apply(lambda s: [g.strip() for g in str(s).split(\",\") if g.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daade9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silent Hill</td>\n",
       "      <td>Horror, Mystery</td>\n",
       "      <td>Rose, a desperate mother takes her adopted dau...</td>\n",
       "      <td>Silent Hill [SEP] Rose, a desperate mother tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breaking the Waves</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>In a small and conservative Scottish village, ...</td>\n",
       "      <td>Breaking the Waves [SEP] In a small and conser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wind Chill</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>Two college students share a ride home for the...</td>\n",
       "      <td>Wind Chill [SEP] Two college students share a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Godmothered</td>\n",
       "      <td>Family, Fantasy, Comedy</td>\n",
       "      <td>A young and unskilled fairy godmother that ven...</td>\n",
       "      <td>Godmothered [SEP] A young and unskilled fairy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donkey Skin</td>\n",
       "      <td>Fantasy, Comedy, Music, Romance</td>\n",
       "      <td>A fairy godmother helps a princess disguise he...</td>\n",
       "      <td>Donkey Skin [SEP] A fairy godmother helps a pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8470</th>\n",
       "      <td>Infested</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>Residents of a rundown French apartment buildi...</td>\n",
       "      <td>Infested [SEP] Residents of a rundown French a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>The Tailor of Panama</td>\n",
       "      <td>Drama, Thriller</td>\n",
       "      <td>A British spy is banished to Panama after havi...</td>\n",
       "      <td>The Tailor of Panama [SEP] A British spy is ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8472</th>\n",
       "      <td>Bad Education</td>\n",
       "      <td>Drama, Crime</td>\n",
       "      <td>An examination on the effect of Franco-era rel...</td>\n",
       "      <td>Bad Education [SEP] An examination on the effe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>From Dusk Till Dawn</td>\n",
       "      <td>Horror, Action, Thriller, Crime</td>\n",
       "      <td>After kidnapping a father and his two kids, th...</td>\n",
       "      <td>From Dusk Till Dawn [SEP] After kidnapping a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>Road Trip</td>\n",
       "      <td>Comedy, Adventure</td>\n",
       "      <td>After an Ithaca College student films his one-...</td>\n",
       "      <td>Road Trip [SEP] After an Ithaca College studen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8475 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie_name                            genre  \\\n",
       "0              Silent Hill                  Horror, Mystery   \n",
       "1       Breaking the Waves                   Drama, Romance   \n",
       "2               Wind Chill          Drama, Horror, Thriller   \n",
       "3              Godmothered          Family, Fantasy, Comedy   \n",
       "4              Donkey Skin  Fantasy, Comedy, Music, Romance   \n",
       "...                    ...                              ...   \n",
       "8470              Infested                 Horror, Thriller   \n",
       "8471  The Tailor of Panama                  Drama, Thriller   \n",
       "8472         Bad Education                     Drama, Crime   \n",
       "8473   From Dusk Till Dawn  Horror, Action, Thriller, Crime   \n",
       "8474             Road Trip                Comedy, Adventure   \n",
       "\n",
       "                                            description  \\\n",
       "0     Rose, a desperate mother takes her adopted dau...   \n",
       "1     In a small and conservative Scottish village, ...   \n",
       "2     Two college students share a ride home for the...   \n",
       "3     A young and unskilled fairy godmother that ven...   \n",
       "4     A fairy godmother helps a princess disguise he...   \n",
       "...                                                 ...   \n",
       "8470  Residents of a rundown French apartment buildi...   \n",
       "8471  A British spy is banished to Panama after havi...   \n",
       "8472  An examination on the effect of Franco-era rel...   \n",
       "8473  After kidnapping a father and his two kids, th...   \n",
       "8474  After an Ithaca College student films his one-...   \n",
       "\n",
       "                                                   text  \n",
       "0     Silent Hill [SEP] Rose, a desperate mother tak...  \n",
       "1     Breaking the Waves [SEP] In a small and conser...  \n",
       "2     Wind Chill [SEP] Two college students share a ...  \n",
       "3     Godmothered [SEP] A young and unskilled fairy ...  \n",
       "4     Donkey Skin [SEP] A fairy godmother helps a pr...  \n",
       "...                                                 ...  \n",
       "8470  Infested [SEP] Residents of a rundown French a...  \n",
       "8471  The Tailor of Panama [SEP] A British spy is ba...  \n",
       "8472  Bad Education [SEP] An examination on the effe...  \n",
       "8473  From Dusk Till Dawn [SEP] After kidnapping a f...  \n",
       "8474  Road Trip [SEP] After an Ithaca College studen...  \n",
       "\n",
       "[8475 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c905898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Horror', 'Mystery']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "239bcf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer() # returns a list per sample with 0/1 for each label\n",
    "Y = mlb.fit_transform(y_list)\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    df[\"text\"], Y, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f88906a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scooby-Doo! Camp Scare [SEP] Scooby and the gang experience outdoor fun as they go back to Fred's old summer camp. As summer goes on, it becomes increasingly clear that the spooky camp stories told by the fireplace, are more real than they've though and soon, it's up to the gang to try and solve the mystery of camp scare.\n",
      "[0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.iloc[0])\n",
    "print(y_tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "836edee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:539: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- TF-IDF word + char ---\n",
    "tfidf_word = TfidfVectorizer(\n",
    "    ngram_range=(1,2), min_df=3, max_features=300_000, sublinear_tf=True, stop_words=\"english\"\n",
    ")\n",
    "tfidf_char = TfidfVectorizer(\n",
    "    analyzer=\"char_wb\", ngram_range=(3,5), min_df=3, max_features=300_000, sublinear_tf=True, stop_words=\"english\"\n",
    ")\n",
    "\n",
    "Xw_tr = tfidf_word.fit_transform(X_tr);  Xw_va = tfidf_word.transform(X_va)\n",
    "Xc_tr = tfidf_char.fit_transform(X_tr);  Xc_va = tfidf_char.transform(X_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ee5b114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11' '11 year' '117' '11th' '12' '12 angry' '12 year' '12 years' '12th'\n",
      " '13']\n",
      "[' \"br' ' \"bu' ' \"c' ' \"ca' ' \"co' ' \"cr' ' \"cu' ' \"d' ' \"da' ' \"de']\n",
      "(7627, 14852) (7627, 62853)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_word.get_feature_names_out()[10:20])\n",
    "print(tfidf_char.get_feature_names_out()[10:20])\n",
    "\n",
    "print(Xw_tr.shape, Xc_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "948a5e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro-F1: 0.6333592534992224\n",
      "macro-F1: 0.555072354314252\n"
     ]
    }
   ],
   "source": [
    "XTR = sp_hstack([Xw_tr, Xc_tr], format=\"csr\")\n",
    "XVA = sp_hstack([Xw_va, Xc_va], format=\"csr\")\n",
    "\n",
    "# --- Clasificador ---\n",
    "clf = OneVsRestClassifier(\n",
    "    LogisticRegression(C=4.0, solver=\"saga\", max_iter=2000, n_jobs=-1),\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(XTR, y_tr)\n",
    "\n",
    "# --- Calibración de umbrales por clase ---\n",
    "logits = clf.decision_function(XVA)  # [n_samples, n_classes]\n",
    "ths = np.zeros(logits.shape[1])\n",
    "for k in range(logits.shape[1]):\n",
    "    s = logits[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1 = f1_score(y_va[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths[k] = best_t\n",
    "\n",
    "pred = (logits >= ths).astype(int)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred, average=\"macro\"))\n",
    "\n",
    "# --- Guardar artefactos para inferencia ---\n",
    "import joblib, json\n",
    "joblib.dump(tfidf_word, \"tfidf_word.joblib\")\n",
    "joblib.dump(tfidf_char, \"tfidf_char.joblib\")\n",
    "joblib.dump(clf, \"ovr_logreg.joblib\")\n",
    "with open(\"labels.json\",\"w\") as f: json.dump(mlb.classes_.tolist(), f)\n",
    "np.save(\"thresholds.npy\", ths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "304c67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_classic.py\n",
    "import pandas as pd, numpy as np, json, joblib\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "tfidf_word = joblib.load(\"tfidf_word.joblib\")\n",
    "tfidf_char = joblib.load(\"tfidf_char.joblib\")\n",
    "clf = joblib.load(\"ovr_logreg.joblib\")\n",
    "labels = json.load(open(\"labels.json\"))\n",
    "ths = np.load(\"thresholds.npy\")\n",
    "\n",
    "def predict(input_csv, output_csv):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    text = df[\"movie_name\"].fillna(\"\") + \" [SEP] \" + df[\"description\"].fillna(\"\")\n",
    "    X = hstack([tfidf_word.transform(text), tfidf_char.transform(text)])\n",
    "    logits = clf.decision_function(X)\n",
    "    pred = (logits >= ths).astype(int)\n",
    "    # Formato: lista de géneros separados por coma\n",
    "    pred_labels = [\",\".join([labels[j] for j,v in enumerate(row) if v==1]) for row in pred]\n",
    "    pd.DataFrame({\"id\": df.index, \"genre\": pred_labels}).to_csv(output_csv, index=False)\n",
    "\n",
    "pathTest = Path(\"../dataset_test.csv\")\n",
    "pathPredict = Path(\"predictions.csv\")\n",
    "predict(pathTest, pathPredict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "083eebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.10141509433962265, 'f1': 0.555072354314252, 'precision': 0.5165202924767383, 'recall': 0.6347798822726912, 'hamming_loss': 0.1235587002096436}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from validator import compute_metrics\n",
    "\n",
    "print(compute_metrics(y_va, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae96f75",
   "metadata": {},
   "source": [
    "## **Comparación de Modelos**\n",
    "\n",
    "Vamos a comparar diferentes clasificadores:\n",
    "1. Logistic Regression con calibración óptima de umbrales (ya entrenado)\n",
    "2. Naive Bayes\n",
    "3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ed3810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODELO 1: Logistic Regression con calibración de umbrales\n",
      "============================================================\n",
      "micro-F1: 0.6333592534992224\n",
      "macro-F1: 0.555072354314252\n",
      "weighted-F1: 0.6458593734356026\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.10141509433962265, 'f1': 0.555072354314252, 'precision': 0.5165202924767383, 'recall': 0.6347798822726912, 'hamming_loss': 0.1235587002096436}\n"
     ]
    }
   ],
   "source": [
    "# Resultados del modelo actual (Logistic Regression con calibración)\n",
    "print(\"=\"*60)\n",
    "print(\"MODELO 1: Logistic Regression con calibración de umbrales\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred, average=\"weighted\"))\n",
    "print(\"\\nMétricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736a0bfe",
   "metadata": {},
   "source": [
    "### **Modelo 2: Naive Bayes (MultinomialNB)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b51ffef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Naive Bayes...\n",
      "\n",
      "============================================================\n",
      "MODELO 2: Naive Bayes (umbral fijo 0.5)\n",
      "============================================================\n",
      "micro-F1: 0.6139965861984882\n",
      "macro-F1: 0.4435358072682958\n",
      "weighted-F1: 0.5934043290825758\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.1615566037735849, 'f1': 0.4435358072682958, 'precision': 0.6055277954176069, 'recall': 0.39046941033006455, 'hamming_loss': 0.10370807127882599}\n",
      "\n",
      "============================================================\n",
      "MODELO 2: Naive Bayes (umbral fijo 0.5)\n",
      "============================================================\n",
      "micro-F1: 0.6139965861984882\n",
      "macro-F1: 0.4435358072682958\n",
      "weighted-F1: 0.5934043290825758\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.1615566037735849, 'f1': 0.4435358072682958, 'precision': 0.6055277954176069, 'recall': 0.39046941033006455, 'hamming_loss': 0.10370807127882599}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Entrenar Naive Bayes\n",
    "clf_nb = OneVsRestClassifier(\n",
    "    MultinomialNB(alpha=0.1),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando Naive Bayes...\")\n",
    "clf_nb.fit(XTR, y_tr)\n",
    "\n",
    "# Predicciones (sin calibración de umbrales, usando probabilidad 0.5)\n",
    "probs_nb = clf_nb.predict_proba(XVA)\n",
    "pred_nb = (probs_nb >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 2: Naive Bayes (umbral fijo 0.5)\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_nb, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_nb, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_nb, average=\"weighted\"))\n",
    "print(\"\\nMétricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9b19d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrando umbrales para Naive Bayes...\n",
      "\n",
      "============================================================\n",
      "MODELO 2: Naive Bayes CON calibración de umbrales\n",
      "============================================================\n",
      "micro-F1: 0.601571802810193\n",
      "macro-F1: 0.4984297864418147\n",
      "weighted-F1: 0.5989285520011974\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.15919811320754718, 'f1': 0.4984297864418147, 'precision': 0.5891897809876009, 'recall': 0.47013391810723815, 'hamming_loss': 0.10960429769392034}\n",
      "\n",
      "============================================================\n",
      "MODELO 2: Naive Bayes CON calibración de umbrales\n",
      "============================================================\n",
      "micro-F1: 0.601571802810193\n",
      "macro-F1: 0.4984297864418147\n",
      "weighted-F1: 0.5989285520011974\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.15919811320754718, 'f1': 0.4984297864418147, 'precision': 0.5891897809876009, 'recall': 0.47013391810723815, 'hamming_loss': 0.10960429769392034}\n"
     ]
    }
   ],
   "source": [
    "# Calibrar umbrales para Naive Bayes (igual que hicimos con Logistic Regression)\n",
    "print(\"Calibrando umbrales para Naive Bayes...\")\n",
    "probs_nb_train = clf_nb.predict_proba(XTR)\n",
    "ths_nb = np.zeros(probs_nb_train.shape[1])\n",
    "\n",
    "for k in range(probs_nb_train.shape[1]):\n",
    "    s = probs_nb_train[:, k]\n",
    "    best_f1, best_t = 0.0, 0.5\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1_tmp = f1_score(y_tr[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1_tmp > best_f1:\n",
    "            best_f1, best_t = f1_tmp, t\n",
    "    ths_nb[k] = best_t\n",
    "\n",
    "# Predicciones con umbrales calibrados\n",
    "pred_nb_cal = (probs_nb >= ths_nb).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 2: Naive Bayes CON calibración de umbrales\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_nb_cal, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_nb_cal, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_nb_cal, average=\"weighted\"))\n",
    "print(\"\\nMétricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_nb_cal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101168e",
   "metadata": {},
   "source": [
    "### **Modelo 3: Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e91eab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Random Forest (esto puede tardar un poco)...\n",
      "\n",
      "============================================================\n",
      "MODELO 3: Random Forest (umbral fijo 0.5)\n",
      "============================================================\n",
      "micro-F1: 0.2544400144980065\n",
      "macro-F1: 0.11725036454742388\n",
      "weighted-F1: 0.21657318624665475\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.04245283018867924, 'f1': 0.11725036454742388, 'precision': 0.5967823535901339, 'recall': 0.07544193117760055, 'hamming_loss': 0.13476153039832284}\n",
      "\n",
      "============================================================\n",
      "MODELO 3: Random Forest (umbral fijo 0.5)\n",
      "============================================================\n",
      "micro-F1: 0.2544400144980065\n",
      "macro-F1: 0.11725036454742388\n",
      "weighted-F1: 0.21657318624665475\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.04245283018867924, 'f1': 0.11725036454742388, 'precision': 0.5967823535901339, 'recall': 0.07544193117760055, 'hamming_loss': 0.13476153039832284}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Entrenar Random Forest (con menos árboles para que no tarde mucho)\n",
    "clf_rf = OneVsRestClassifier(\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=20, n_jobs=-1, random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando Random Forest (esto puede tardar un poco)...\")\n",
    "clf_rf.fit(XTR, y_tr)\n",
    "\n",
    "# Predicciones (sin calibración de umbrales, usando probabilidad 0.5)\n",
    "probs_rf = clf_rf.predict_proba(XVA)\n",
    "pred_rf = (probs_rf >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 3: Random Forest (umbral fijo 0.5)\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_rf, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_rf, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_rf, average=\"weighted\"))\n",
    "print(\"\\nMétricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "621f08d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrando umbrales para Random Forest...\n",
      "\n",
      "============================================================\n",
      "MODELO 3: Random Forest CON calibración de umbrales\n",
      "============================================================\n",
      "micro-F1: 0.5444832545716047\n",
      "macro-F1: 0.47330195719224744\n",
      "weighted-F1: 0.5649687243743775\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.06721698113207547, 'f1': 0.47330195719224744, 'precision': 0.4553511035206816, 'recall': 0.5525472162644545, 'hamming_loss': 0.1452437106918239}\n",
      "\n",
      "============================================================\n",
      "MODELO 3: Random Forest CON calibración de umbrales\n",
      "============================================================\n",
      "micro-F1: 0.5444832545716047\n",
      "macro-F1: 0.47330195719224744\n",
      "weighted-F1: 0.5649687243743775\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.06721698113207547, 'f1': 0.47330195719224744, 'precision': 0.4553511035206816, 'recall': 0.5525472162644545, 'hamming_loss': 0.1452437106918239}\n"
     ]
    }
   ],
   "source": [
    "# Calibrar umbrales para Random Forest\n",
    "print(\"Calibrando umbrales para Random Forest...\")\n",
    "probs_rf_train = clf_rf.predict_proba(XTR)\n",
    "ths_rf = np.zeros(probs_rf_train.shape[1])\n",
    "\n",
    "for k in range(probs_rf_train.shape[1]):\n",
    "    s = probs_rf_train[:, k]\n",
    "    best_f1, best_t = 0.0, 0.5\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1_tmp = f1_score(y_tr[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1_tmp > best_f1:\n",
    "            best_f1, best_t = f1_tmp, t\n",
    "    ths_rf[k] = best_t\n",
    "\n",
    "# Predicciones con umbrales calibrados\n",
    "pred_rf_cal = (probs_rf >= ths_rf).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 3: Random Forest CON calibración de umbrales\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_rf_cal, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_rf_cal, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_rf_cal, average=\"weighted\"))\n",
    "print(\"\\nMétricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_rf_cal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30956fcb",
   "metadata": {},
   "source": [
    "### **Resumen Comparativo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee5c313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESUMEN COMPARATIVO DE MODELOS\n",
      "================================================================================\n",
      "Modelo                                  Micro-F1     Macro-F1  Weighted-F1\n",
      "--------------------------------------------------------------------------------\n",
      "Logistic Regression + calibración         0.6334       0.5551       0.6459\n",
      "Naive Bayes (umbral 0.5)                  0.6140       0.4435       0.5934\n",
      "Naive Bayes + calibración                 0.6016       0.4984       0.5989\n",
      "Random Forest (umbral 0.5)                0.2544       0.1173       0.2166\n",
      "Random Forest + calibración               0.5445       0.4733       0.5650\n",
      "================================================================================\n",
      "\n",
      "Mejor modelo por Micro-F1:\n",
      "                              Modelo  Micro-F1  Macro-F1  Weighted-F1\n",
      "0  Logistic Regression + calibración  0.633359  0.555072     0.645859\n"
     ]
    }
   ],
   "source": [
    "# Crear tabla comparativa\n",
    "results = []\n",
    "\n",
    "models = [\n",
    "    (\"Logistic Regression + calibración\", pred),\n",
    "    (\"Naive Bayes (umbral 0.5)\", pred_nb),\n",
    "    (\"Naive Bayes + calibración\", pred_nb_cal),\n",
    "    (\"Random Forest (umbral 0.5)\", pred_rf),\n",
    "    (\"Random Forest + calibración\", pred_rf_cal)\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESUMEN COMPARATIVO DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Modelo':<35} {'Micro-F1':>12} {'Macro-F1':>12} {'Weighted-F1':>12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for name, predictions in models:\n",
    "    micro = f1_score(y_va, predictions, average=\"micro\")\n",
    "    macro = f1_score(y_va, predictions, average=\"macro\")\n",
    "    weighted = f1_score(y_va, predictions, average=\"weighted\")\n",
    "    print(f\"{name:<35} {micro:>12.4f} {macro:>12.4f} {weighted:>12.4f}\")\n",
    "    results.append({\n",
    "        'Modelo': name,\n",
    "        'Micro-F1': micro,\n",
    "        'Macro-F1': macro,\n",
    "        'Weighted-F1': weighted\n",
    "    })\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear DataFrame para mejor visualización\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values('Micro-F1', ascending=False)\n",
    "print(\"\\nMejor modelo por Micro-F1:\")\n",
    "print(df_results.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ef371",
   "metadata": {},
   "source": [
    "## **Comparación con CountVectorizer**\n",
    "\n",
    "Ahora vamos a probar los mismos modelos pero usando **CountVectorizer** en lugar de TF-IDF para ver si hay diferencias en el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc61efb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando con CountVectorizer...\n",
      "Shape: (7627, 77705)\n",
      "Shape: (7627, 77705)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# --- CountVectorizer word + char ---\n",
    "count_word = CountVectorizer(\n",
    "    ngram_range=(1,2), min_df=3, max_features=300_000, stop_words=\"english\"\n",
    ")\n",
    "count_char = CountVectorizer(\n",
    "    analyzer=\"char_wb\", ngram_range=(3,5), min_df=3, max_features=300_000\n",
    ")\n",
    "\n",
    "print(\"Transformando con CountVectorizer...\")\n",
    "Xw_tr_count = count_word.fit_transform(X_tr);  Xw_va_count = count_word.transform(X_va)\n",
    "Xc_tr_count = count_char.fit_transform(X_tr);  Xc_va_count = count_char.transform(X_va)\n",
    "\n",
    "# Combinar word + char\n",
    "XTR_count = sp_hstack([Xw_tr_count, Xc_tr_count], format=\"csr\")\n",
    "XVA_count = sp_hstack([Xw_va_count, Xc_va_count], format=\"csr\")\n",
    "\n",
    "print(f\"Shape: {XTR_count.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d761c7",
   "metadata": {},
   "source": [
    "### **Modelo 1: Logistic Regression con CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a419216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Logistic Regression con CountVectorizer...\n",
      "\n",
      "============================================================\n",
      "Logistic Regression + CountVectorizer + calibración\n",
      "============================================================\n",
      "micro-F1: 0.5911634188693806\n",
      "macro-F1: 0.5084452569620344\n",
      "weighted-F1: 0.5947186263714275\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.08254716981132075, 'f1': 0.5084452569620344, 'precision': 0.46659793173969966, 'recall': 0.587063405690667, 'hamming_loss': 0.13882337526205452}\n",
      "\n",
      "============================================================\n",
      "Logistic Regression + CountVectorizer + calibración\n",
      "============================================================\n",
      "micro-F1: 0.5911634188693806\n",
      "macro-F1: 0.5084452569620344\n",
      "weighted-F1: 0.5947186263714275\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.08254716981132075, 'f1': 0.5084452569620344, 'precision': 0.46659793173969966, 'recall': 0.587063405690667, 'hamming_loss': 0.13882337526205452}\n"
     ]
    }
   ],
   "source": [
    "# Entrenar Logistic Regression con CountVectorizer\n",
    "clf_lr_count = OneVsRestClassifier(\n",
    "    LogisticRegression(C=4.0, solver=\"saga\", max_iter=2000, n_jobs=-1),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando Logistic Regression con CountVectorizer...\")\n",
    "clf_lr_count.fit(XTR_count, y_tr)\n",
    "\n",
    "# Calibración de umbrales\n",
    "logits_count = clf_lr_count.decision_function(XVA_count)\n",
    "ths_lr_count = np.zeros(logits_count.shape[1])\n",
    "\n",
    "for k in range(logits_count.shape[1]):\n",
    "    s = logits_count[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1_tmp = f1_score(y_va[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1_tmp > best_f1:\n",
    "            best_f1, best_t = f1_tmp, t\n",
    "    ths_lr_count[k] = best_t\n",
    "\n",
    "pred_lr_count = (logits_count >= ths_lr_count).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Logistic Regression + CountVectorizer + calibración\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_lr_count, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_lr_count, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_lr_count, average=\"weighted\"))\n",
    "print(\"\\nMétricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_lr_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fff470",
   "metadata": {},
   "source": [
    "### **Modelo 2: Naive Bayes con CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27a4683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Naive Bayes con CountVectorizer...\n",
      "\n",
      "============================================================\n",
      "Naive Bayes + CountVectorizer + calibración\n",
      "============================================================\n",
      "micro-F1: 0.6006148025537952\n",
      "macro-F1: 0.5039395423835606\n",
      "weighted-F1: 0.6010710781338638\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.1403301886792453, 'f1': 0.5039395423835606, 'precision': 0.5736236925916347, 'recall': 0.48357022889873424, 'hamming_loss': 0.11065251572327044}\n",
      "\n",
      "============================================================\n",
      "Naive Bayes + CountVectorizer + calibración\n",
      "============================================================\n",
      "micro-F1: 0.6006148025537952\n",
      "macro-F1: 0.5039395423835606\n",
      "weighted-F1: 0.6010710781338638\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.1403301886792453, 'f1': 0.5039395423835606, 'precision': 0.5736236925916347, 'recall': 0.48357022889873424, 'hamming_loss': 0.11065251572327044}\n"
     ]
    }
   ],
   "source": [
    "# Entrenar Naive Bayes con CountVectorizer\n",
    "clf_nb_count = OneVsRestClassifier(\n",
    "    MultinomialNB(alpha=0.1),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando Naive Bayes con CountVectorizer...\")\n",
    "clf_nb_count.fit(XTR_count, y_tr)\n",
    "\n",
    "# Calibración de umbrales\n",
    "probs_nb_count = clf_nb_count.predict_proba(XVA_count)\n",
    "probs_nb_count_train = clf_nb_count.predict_proba(XTR_count)\n",
    "ths_nb_count = np.zeros(probs_nb_count_train.shape[1])\n",
    "\n",
    "for k in range(probs_nb_count_train.shape[1]):\n",
    "    s = probs_nb_count_train[:, k]\n",
    "    best_f1, best_t = 0.0, 0.5\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1_tmp = f1_score(y_tr[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1_tmp > best_f1:\n",
    "            best_f1, best_t = f1_tmp, t\n",
    "    ths_nb_count[k] = best_t\n",
    "\n",
    "pred_nb_count = (probs_nb_count >= ths_nb_count).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Naive Bayes + CountVectorizer + calibración\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_nb_count, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_nb_count, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_nb_count, average=\"weighted\"))\n",
    "print(\"\\nMétricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_nb_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196213c5",
   "metadata": {},
   "source": [
    "### **Modelo 3: Random Forest con CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4aca3ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Random Forest con CountVectorizer (esto puede tardar un poco)...\n",
      "\n",
      "============================================================\n",
      "Random Forest + CountVectorizer + calibración\n",
      "============================================================\n",
      "micro-F1: 0.5626009693053312\n",
      "macro-F1: 0.47467920256782326\n",
      "weighted-F1: 0.5740550901842221\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.09080188679245282, 'f1': 0.47467920256782326, 'precision': 0.44896292823722495, 'recall': 0.5415173911309075, 'hamming_loss': 0.14190251572327045}\n",
      "\n",
      "============================================================\n",
      "Random Forest + CountVectorizer + calibración\n",
      "============================================================\n",
      "micro-F1: 0.5626009693053312\n",
      "macro-F1: 0.47467920256782326\n",
      "weighted-F1: 0.5740550901842221\n",
      "\n",
      "Métricas detalladas:\n",
      "{'accuracy': 0.09080188679245282, 'f1': 0.47467920256782326, 'precision': 0.44896292823722495, 'recall': 0.5415173911309075, 'hamming_loss': 0.14190251572327045}\n"
     ]
    }
   ],
   "source": [
    "# Entrenar Random Forest con CountVectorizer\n",
    "clf_rf_count = OneVsRestClassifier(\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=20, n_jobs=-1, random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando Random Forest con CountVectorizer (esto puede tardar un poco)...\")\n",
    "clf_rf_count.fit(XTR_count, y_tr)\n",
    "\n",
    "# Calibración de umbrales\n",
    "probs_rf_count = clf_rf_count.predict_proba(XVA_count)\n",
    "probs_rf_count_train = clf_rf_count.predict_proba(XTR_count)\n",
    "ths_rf_count = np.zeros(probs_rf_count_train.shape[1])\n",
    "\n",
    "for k in range(probs_rf_count_train.shape[1]):\n",
    "    s = probs_rf_count_train[:, k]\n",
    "    best_f1, best_t = 0.0, 0.5\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1_tmp = f1_score(y_tr[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1_tmp > best_f1:\n",
    "            best_f1, best_t = f1_tmp, t\n",
    "    ths_rf_count[k] = best_t\n",
    "\n",
    "pred_rf_count = (probs_rf_count >= ths_rf_count).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Random Forest + CountVectorizer + calibración\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_rf_count, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_rf_count, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_rf_count, average=\"weighted\"))\n",
    "print(\"\\nMétricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_rf_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545a573",
   "metadata": {},
   "source": [
    "### **Resumen Comparativo: TF-IDF vs CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78107cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "COMPARACIÓN COMPLETA: TF-IDF vs CountVectorizer\n",
      "=====================================================================================\n",
      "Modelo                                            Micro-F1     Macro-F1  Weighted-F1\n",
      "-------------------------------------------------------------------------------------\n",
      "TF-IDF: Logistic Regression + calibración           0.6334       0.5551       0.6459\n",
      "TF-IDF: Naive Bayes (umbral 0.5)                    0.6140       0.4435       0.5934\n",
      "TF-IDF: Naive Bayes + calibración                   0.6016       0.4984       0.5989\n",
      "TF-IDF: Random Forest (umbral 0.5)                  0.2544       0.1173       0.2166\n",
      "TF-IDF: Random Forest + calibración                 0.5445       0.4733       0.5650\n",
      "Count: Logistic Regression + calibración            0.5912       0.5084       0.5947\n",
      "Count: Naive Bayes + calibración                    0.6006       0.5039       0.6011\n",
      "Count: Random Forest + calibración                  0.5626       0.4747       0.5741\n",
      "=====================================================================================\n",
      "\n",
      "🏆 TOP 3 MODELOS (por Micro-F1):\n",
      "                                   Modelo  Micro-F1  Macro-F1  Weighted-F1\n",
      "TF-IDF: Logistic Regression + calibración  0.633359  0.555072     0.645859\n",
      "         TF-IDF: Naive Bayes (umbral 0.5)  0.613997  0.443536     0.593404\n",
      "        TF-IDF: Naive Bayes + calibración  0.601572  0.498430     0.598929\n",
      "\n",
      "📊 Comparación por vectorizador:\n",
      "Promedio TF-IDF: 0.5296\n",
      "Promedio CountVectorizer: 0.5848\n"
     ]
    }
   ],
   "source": [
    "# Comparación completa: TF-IDF vs CountVectorizer\n",
    "all_models = [\n",
    "    # TF-IDF\n",
    "    (\"TF-IDF: Logistic Regression + calibración\", pred),\n",
    "    (\"TF-IDF: Naive Bayes (umbral 0.5)\", pred_nb),\n",
    "    (\"TF-IDF: Naive Bayes + calibración\", pred_nb_cal),\n",
    "    (\"TF-IDF: Random Forest (umbral 0.5)\", pred_rf),\n",
    "    (\"TF-IDF: Random Forest + calibración\", pred_rf_cal),\n",
    "    # CountVectorizer\n",
    "    (\"Count: Logistic Regression + calibración\", pred_lr_count),\n",
    "    (\"Count: Naive Bayes + calibración\", pred_nb_count),\n",
    "    (\"Count: Random Forest + calibración\", pred_rf_count),\n",
    "]\n",
    "\n",
    "print(\"=\"*85)\n",
    "print(\"COMPARACIÓN COMPLETA: TF-IDF vs CountVectorizer\")\n",
    "print(\"=\"*85)\n",
    "print(f\"{'Modelo':<45} {'Micro-F1':>12} {'Macro-F1':>12} {'Weighted-F1':>12}\")\n",
    "print(\"-\"*85)\n",
    "\n",
    "all_results = []\n",
    "for name, predictions in all_models:\n",
    "    micro = f1_score(y_va, predictions, average=\"micro\")\n",
    "    macro = f1_score(y_va, predictions, average=\"macro\")\n",
    "    weighted = f1_score(y_va, predictions, average=\"weighted\")\n",
    "    print(f\"{name:<45} {micro:>12.4f} {macro:>12.4f} {weighted:>12.4f}\")\n",
    "    all_results.append({\n",
    "        'Modelo': name,\n",
    "        'Micro-F1': micro,\n",
    "        'Macro-F1': macro,\n",
    "        'Weighted-F1': weighted\n",
    "    })\n",
    "\n",
    "print(\"=\"*85)\n",
    "\n",
    "# Crear DataFrame ordenado por Micro-F1\n",
    "df_all_results = pd.DataFrame(all_results)\n",
    "df_all_results = df_all_results.sort_values('Micro-F1', ascending=False)\n",
    "\n",
    "print(\"\\n🏆 TOP 3 MODELOS (por Micro-F1):\")\n",
    "print(df_all_results.head(3).to_string(index=False))\n",
    "\n",
    "print(\"\\n📊 Comparación por vectorizador:\")\n",
    "tfidf_avg = df_all_results[df_all_results['Modelo'].str.contains('TF-IDF')]['Micro-F1'].mean()\n",
    "count_avg = df_all_results[df_all_results['Modelo'].str.contains('Count')]['Micro-F1'].mean()\n",
    "print(f\"Promedio TF-IDF: {tfidf_avg:.4f}\")\n",
    "print(f\"Promedio CountVectorizer: {count_avg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
