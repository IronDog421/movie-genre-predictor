{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "571652b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.sparse import hstack as sp_hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd46d3",
   "metadata": {},
   "source": [
    "### **Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a871de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = Path(\"../dataset_test.csv\")\n",
    "train_dir = Path(\"../dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0adbcb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8475"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(train_dir)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43ee1a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silent Hill</td>\n",
       "      <td>Horror, Mystery</td>\n",
       "      <td>Rose, a desperate mother takes her adopted dau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breaking the Waves</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>In a small and conservative Scottish village, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wind Chill</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>Two college students share a ride home for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Godmothered</td>\n",
       "      <td>Family, Fantasy, Comedy</td>\n",
       "      <td>A young and unskilled fairy godmother that ven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donkey Skin</td>\n",
       "      <td>Fantasy, Comedy, Music, Romance</td>\n",
       "      <td>A fairy godmother helps a princess disguise he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8470</th>\n",
       "      <td>Infested</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>Residents of a rundown French apartment buildi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>The Tailor of Panama</td>\n",
       "      <td>Drama, Thriller</td>\n",
       "      <td>A British spy is banished to Panama after havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8472</th>\n",
       "      <td>Bad Education</td>\n",
       "      <td>Drama, Crime</td>\n",
       "      <td>An examination on the effect of Franco-era rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>From Dusk Till Dawn</td>\n",
       "      <td>Horror, Action, Thriller, Crime</td>\n",
       "      <td>After kidnapping a father and his two kids, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>Road Trip</td>\n",
       "      <td>Comedy, Adventure</td>\n",
       "      <td>After an Ithaca College student films his one-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8475 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie_name                            genre  \\\n",
       "0              Silent Hill                  Horror, Mystery   \n",
       "1       Breaking the Waves                   Drama, Romance   \n",
       "2               Wind Chill          Drama, Horror, Thriller   \n",
       "3              Godmothered          Family, Fantasy, Comedy   \n",
       "4              Donkey Skin  Fantasy, Comedy, Music, Romance   \n",
       "...                    ...                              ...   \n",
       "8470              Infested                 Horror, Thriller   \n",
       "8471  The Tailor of Panama                  Drama, Thriller   \n",
       "8472         Bad Education                     Drama, Crime   \n",
       "8473   From Dusk Till Dawn  Horror, Action, Thriller, Crime   \n",
       "8474             Road Trip                Comedy, Adventure   \n",
       "\n",
       "                                            description  \n",
       "0     Rose, a desperate mother takes her adopted dau...  \n",
       "1     In a small and conservative Scottish village, ...  \n",
       "2     Two college students share a ride home for the...  \n",
       "3     A young and unskilled fairy godmother that ven...  \n",
       "4     A fairy godmother helps a princess disguise he...  \n",
       "...                                                 ...  \n",
       "8470  Residents of a rundown French apartment buildi...  \n",
       "8471  A British spy is banished to Panama after havi...  \n",
       "8472  An examination on the effect of Franco-era rel...  \n",
       "8473  After kidnapping a father and his two kids, th...  \n",
       "8474  After an Ithaca College student films his one-...  \n",
       "\n",
       "[8475 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5793b",
   "metadata": {},
   "source": [
    "## **Text to disperse vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f703f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"movie_name\"].fillna(\"\") + \" [SEP] \" + df[\"description\"].fillna(\"\")\n",
    "y_list = df[\"genre\"].apply(lambda s: [g.strip() for g in str(s).split(\",\") if g.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daade9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silent Hill</td>\n",
       "      <td>Horror, Mystery</td>\n",
       "      <td>Rose, a desperate mother takes her adopted dau...</td>\n",
       "      <td>Silent Hill [SEP] Rose, a desperate mother tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breaking the Waves</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>In a small and conservative Scottish village, ...</td>\n",
       "      <td>Breaking the Waves [SEP] In a small and conser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wind Chill</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>Two college students share a ride home for the...</td>\n",
       "      <td>Wind Chill [SEP] Two college students share a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Godmothered</td>\n",
       "      <td>Family, Fantasy, Comedy</td>\n",
       "      <td>A young and unskilled fairy godmother that ven...</td>\n",
       "      <td>Godmothered [SEP] A young and unskilled fairy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donkey Skin</td>\n",
       "      <td>Fantasy, Comedy, Music, Romance</td>\n",
       "      <td>A fairy godmother helps a princess disguise he...</td>\n",
       "      <td>Donkey Skin [SEP] A fairy godmother helps a pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8470</th>\n",
       "      <td>Infested</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>Residents of a rundown French apartment buildi...</td>\n",
       "      <td>Infested [SEP] Residents of a rundown French a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>The Tailor of Panama</td>\n",
       "      <td>Drama, Thriller</td>\n",
       "      <td>A British spy is banished to Panama after havi...</td>\n",
       "      <td>The Tailor of Panama [SEP] A British spy is ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8472</th>\n",
       "      <td>Bad Education</td>\n",
       "      <td>Drama, Crime</td>\n",
       "      <td>An examination on the effect of Franco-era rel...</td>\n",
       "      <td>Bad Education [SEP] An examination on the effe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>From Dusk Till Dawn</td>\n",
       "      <td>Horror, Action, Thriller, Crime</td>\n",
       "      <td>After kidnapping a father and his two kids, th...</td>\n",
       "      <td>From Dusk Till Dawn [SEP] After kidnapping a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>Road Trip</td>\n",
       "      <td>Comedy, Adventure</td>\n",
       "      <td>After an Ithaca College student films his one-...</td>\n",
       "      <td>Road Trip [SEP] After an Ithaca College studen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8475 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie_name                            genre  \\\n",
       "0              Silent Hill                  Horror, Mystery   \n",
       "1       Breaking the Waves                   Drama, Romance   \n",
       "2               Wind Chill          Drama, Horror, Thriller   \n",
       "3              Godmothered          Family, Fantasy, Comedy   \n",
       "4              Donkey Skin  Fantasy, Comedy, Music, Romance   \n",
       "...                    ...                              ...   \n",
       "8470              Infested                 Horror, Thriller   \n",
       "8471  The Tailor of Panama                  Drama, Thriller   \n",
       "8472         Bad Education                     Drama, Crime   \n",
       "8473   From Dusk Till Dawn  Horror, Action, Thriller, Crime   \n",
       "8474             Road Trip                Comedy, Adventure   \n",
       "\n",
       "                                            description  \\\n",
       "0     Rose, a desperate mother takes her adopted dau...   \n",
       "1     In a small and conservative Scottish village, ...   \n",
       "2     Two college students share a ride home for the...   \n",
       "3     A young and unskilled fairy godmother that ven...   \n",
       "4     A fairy godmother helps a princess disguise he...   \n",
       "...                                                 ...   \n",
       "8470  Residents of a rundown French apartment buildi...   \n",
       "8471  A British spy is banished to Panama after havi...   \n",
       "8472  An examination on the effect of Franco-era rel...   \n",
       "8473  After kidnapping a father and his two kids, th...   \n",
       "8474  After an Ithaca College student films his one-...   \n",
       "\n",
       "                                                   text  \n",
       "0     Silent Hill [SEP] Rose, a desperate mother tak...  \n",
       "1     Breaking the Waves [SEP] In a small and conser...  \n",
       "2     Wind Chill [SEP] Two college students share a ...  \n",
       "3     Godmothered [SEP] A young and unskilled fairy ...  \n",
       "4     Donkey Skin [SEP] A fairy godmother helps a pr...  \n",
       "...                                                 ...  \n",
       "8470  Infested [SEP] Residents of a rundown French a...  \n",
       "8471  The Tailor of Panama [SEP] A British spy is ba...  \n",
       "8472  Bad Education [SEP] An examination on the effe...  \n",
       "8473  From Dusk Till Dawn [SEP] After kidnapping a f...  \n",
       "8474  Road Trip [SEP] After an Ithaca College studen...  \n",
       "\n",
       "[8475 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c905898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Horror', 'Mystery']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "239bcf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer() # returns a list per sample with 0/1 for each label\n",
    "Y = mlb.fit_transform(y_list)\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    df[\"text\"], Y, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f88906a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scooby-Doo! Camp Scare [SEP] Scooby and the gang experience outdoor fun as they go back to Fred's old summer camp. As summer goes on, it becomes increasingly clear that the spooky camp stories told by the fireplace, are more real than they've though and soon, it's up to the gang to try and solve the mystery of camp scare.\n",
      "[0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.iloc[0])\n",
    "print(y_tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "836edee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:539: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- TF-IDF word + char ---\n",
    "tfidf_word = TfidfVectorizer(\n",
    "    ngram_range=(1,2), min_df=3, max_features=300_000, sublinear_tf=True, stop_words=\"english\"\n",
    ")\n",
    "tfidf_char = TfidfVectorizer(\n",
    "    analyzer=\"char_wb\", ngram_range=(3,5), min_df=3, max_features=300_000, sublinear_tf=True, stop_words=\"english\"\n",
    ")\n",
    "\n",
    "Xw_tr = tfidf_word.fit_transform(X_tr);  Xw_va = tfidf_word.transform(X_va)\n",
    "Xc_tr = tfidf_char.fit_transform(X_tr);  Xc_va = tfidf_char.transform(X_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ee5b114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11' '11 year' '117' '11th' '12' '12 angry' '12 year' '12 years' '12th'\n",
      " '13']\n",
      "[' \"br' ' \"bu' ' \"c' ' \"ca' ' \"co' ' \"cr' ' \"cu' ' \"d' ' \"da' ' \"de']\n",
      "(7627, 14852) (7627, 62853)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_word.get_feature_names_out()[10:20])\n",
    "print(tfidf_char.get_feature_names_out()[10:20])\n",
    "\n",
    "print(Xw_tr.shape, Xc_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "948a5e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro-F1: 0.6333592534992224\n",
      "macro-F1: 0.555072354314252\n"
     ]
    }
   ],
   "source": [
    "XTR = sp_hstack([Xw_tr, Xc_tr], format=\"csr\")\n",
    "XVA = sp_hstack([Xw_va, Xc_va], format=\"csr\")\n",
    "\n",
    "# --- Clasificador ---\n",
    "clf = OneVsRestClassifier(\n",
    "    LogisticRegression(C=4.0, solver=\"saga\", max_iter=2000, n_jobs=-1),\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(XTR, y_tr)\n",
    "\n",
    "# --- Calibraci贸n de umbrales por clase ---\n",
    "logits = clf.decision_function(XVA)  # [n_samples, n_classes]\n",
    "ths = np.zeros(logits.shape[1])\n",
    "for k in range(logits.shape[1]):\n",
    "    s = logits[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1 = f1_score(y_va[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths[k] = best_t\n",
    "\n",
    "pred = (logits >= ths).astype(int)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred, average=\"macro\"))\n",
    "\n",
    "# --- Guardar artefactos para inferencia ---\n",
    "import joblib, json\n",
    "joblib.dump(tfidf_word, \"tfidf_word.joblib\")\n",
    "joblib.dump(tfidf_char, \"tfidf_char.joblib\")\n",
    "joblib.dump(clf, \"ovr_logreg.joblib\")\n",
    "with open(\"labels.json\",\"w\") as f: json.dump(mlb.classes_.tolist(), f)\n",
    "np.save(\"thresholds.npy\", ths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "304c67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_classic.py\n",
    "import pandas as pd, numpy as np, json, joblib\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "tfidf_word = joblib.load(\"tfidf_word.joblib\")\n",
    "tfidf_char = joblib.load(\"tfidf_char.joblib\")\n",
    "clf = joblib.load(\"ovr_logreg.joblib\")\n",
    "labels = json.load(open(\"labels.json\"))\n",
    "ths = np.load(\"thresholds.npy\")\n",
    "\n",
    "def predict(input_csv, output_csv):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    text = df[\"movie_name\"].fillna(\"\") + \" [SEP] \" + df[\"description\"].fillna(\"\")\n",
    "    X = hstack([tfidf_word.transform(text), tfidf_char.transform(text)])\n",
    "    logits = clf.decision_function(X)\n",
    "    pred = (logits >= ths).astype(int)\n",
    "    # Formato: lista de g茅neros separados por coma\n",
    "    pred_labels = [\",\".join([labels[j] for j,v in enumerate(row) if v==1]) for row in pred]\n",
    "    pd.DataFrame({\"id\": df.index, \"genre\": pred_labels}).to_csv(output_csv, index=False)\n",
    "\n",
    "pathTest = Path(\"../dataset_test.csv\")\n",
    "pathPredict = Path(\"predictions.csv\")\n",
    "predict(pathTest, pathPredict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "083eebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.10141509433962265, 'f1': 0.555072354314252, 'precision': 0.5165202924767383, 'recall': 0.6347798822726912, 'hamming_loss': 0.1235587002096436}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from validator import compute_metrics\n",
    "\n",
    "print(compute_metrics(y_va, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae96f75",
   "metadata": {},
   "source": [
    "## **Comparaci贸n de Modelos**\n",
    "\n",
    "Vamos a comparar diferentes clasificadores:\n",
    "1. Logistic Regression con calibraci贸n 贸ptima de umbrales (ya entrenado)\n",
    "2. Naive Bayes\n",
    "3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ed3810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODELO 1: Logistic Regression con calibraci贸n de umbrales\n",
      "============================================================\n",
      "micro-F1: 0.6333592534992224\n",
      "macro-F1: 0.555072354314252\n",
      "weighted-F1: 0.6458593734356026\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.10141509433962265, 'f1': 0.555072354314252, 'precision': 0.5165202924767383, 'recall': 0.6347798822726912, 'hamming_loss': 0.1235587002096436}\n"
     ]
    }
   ],
   "source": [
    "# Resultados del modelo actual (Logistic Regression con calibraci贸n)\n",
    "print(\"=\"*60)\n",
    "print(\"MODELO 1: Logistic Regression con calibraci贸n de umbrales\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred, average=\"weighted\"))\n",
    "print(\"\\nM茅tricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736a0bfe",
   "metadata": {},
   "source": [
    "### **Modelo 2: Naive Bayes (MultinomialNB)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b51ffef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Naive Bayes...\n",
      "\n",
      "============================================================\n",
      "MODELO 2: Naive Bayes (umbral fijo 0.5)\n",
      "============================================================\n",
      "micro-F1: 0.6139965861984882\n",
      "macro-F1: 0.4435358072682958\n",
      "weighted-F1: 0.5934043290825758\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.1615566037735849, 'f1': 0.4435358072682958, 'precision': 0.6055277954176069, 'recall': 0.39046941033006455, 'hamming_loss': 0.10370807127882599}\n",
      "\n",
      "============================================================\n",
      "MODELO 2: Naive Bayes (umbral fijo 0.5)\n",
      "============================================================\n",
      "micro-F1: 0.6139965861984882\n",
      "macro-F1: 0.4435358072682958\n",
      "weighted-F1: 0.5934043290825758\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.1615566037735849, 'f1': 0.4435358072682958, 'precision': 0.6055277954176069, 'recall': 0.39046941033006455, 'hamming_loss': 0.10370807127882599}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Entrenar Naive Bayes\n",
    "clf_nb = OneVsRestClassifier(\n",
    "    MultinomialNB(alpha=0.1),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando Naive Bayes...\")\n",
    "clf_nb.fit(XTR, y_tr)\n",
    "\n",
    "# Predicciones (sin calibraci贸n de umbrales, usando probabilidad 0.5)\n",
    "probs_nb = clf_nb.predict_proba(XVA)\n",
    "pred_nb = (probs_nb >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 2: Naive Bayes (umbral fijo 0.5)\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_nb, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_nb, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_nb, average=\"weighted\"))\n",
    "print(\"\\nM茅tricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9b19d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrando umbrales para Naive Bayes...\n",
      "\n",
      "============================================================\n",
      "MODELO 2: Naive Bayes CON calibraci贸n de umbrales\n",
      "============================================================\n",
      "micro-F1: 0.601571802810193\n",
      "macro-F1: 0.4984297864418147\n",
      "weighted-F1: 0.5989285520011974\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.15919811320754718, 'f1': 0.4984297864418147, 'precision': 0.5891897809876009, 'recall': 0.47013391810723815, 'hamming_loss': 0.10960429769392034}\n",
      "\n",
      "============================================================\n",
      "MODELO 2: Naive Bayes CON calibraci贸n de umbrales\n",
      "============================================================\n",
      "micro-F1: 0.601571802810193\n",
      "macro-F1: 0.4984297864418147\n",
      "weighted-F1: 0.5989285520011974\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.15919811320754718, 'f1': 0.4984297864418147, 'precision': 0.5891897809876009, 'recall': 0.47013391810723815, 'hamming_loss': 0.10960429769392034}\n"
     ]
    }
   ],
   "source": [
    "# Calibrar umbrales para Naive Bayes (igual que hicimos con Logistic Regression)\n",
    "print(\"Calibrando umbrales para Naive Bayes...\")\n",
    "probs_nb_train = clf_nb.predict_proba(XTR)\n",
    "ths_nb = np.zeros(probs_nb_train.shape[1])\n",
    "\n",
    "for k in range(probs_nb_train.shape[1]):\n",
    "    s = probs_nb_train[:, k]\n",
    "    best_f1, best_t = 0.0, 0.5\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1_tmp = f1_score(y_tr[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1_tmp > best_f1:\n",
    "            best_f1, best_t = f1_tmp, t\n",
    "    ths_nb[k] = best_t\n",
    "\n",
    "# Predicciones con umbrales calibrados\n",
    "pred_nb_cal = (probs_nb >= ths_nb).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 2: Naive Bayes CON calibraci贸n de umbrales\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_nb_cal, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_nb_cal, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_nb_cal, average=\"weighted\"))\n",
    "print(\"\\nM茅tricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_nb_cal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101168e",
   "metadata": {},
   "source": [
    "### **Modelo 3: Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e91eab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Random Forest (esto puede tardar un poco)...\n",
      "\n",
      "============================================================\n",
      "MODELO 3: Random Forest (umbral fijo 0.5)\n",
      "============================================================\n",
      "micro-F1: 0.2544400144980065\n",
      "macro-F1: 0.11725036454742388\n",
      "weighted-F1: 0.21657318624665475\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.04245283018867924, 'f1': 0.11725036454742388, 'precision': 0.5967823535901339, 'recall': 0.07544193117760055, 'hamming_loss': 0.13476153039832284}\n",
      "\n",
      "============================================================\n",
      "MODELO 3: Random Forest (umbral fijo 0.5)\n",
      "============================================================\n",
      "micro-F1: 0.2544400144980065\n",
      "macro-F1: 0.11725036454742388\n",
      "weighted-F1: 0.21657318624665475\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.04245283018867924, 'f1': 0.11725036454742388, 'precision': 0.5967823535901339, 'recall': 0.07544193117760055, 'hamming_loss': 0.13476153039832284}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Entrenar Random Forest (con menos 谩rboles para que no tarde mucho)\n",
    "clf_rf = OneVsRestClassifier(\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=20, n_jobs=-1, random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando Random Forest (esto puede tardar un poco)...\")\n",
    "clf_rf.fit(XTR, y_tr)\n",
    "\n",
    "# Predicciones (sin calibraci贸n de umbrales, usando probabilidad 0.5)\n",
    "probs_rf = clf_rf.predict_proba(XVA)\n",
    "pred_rf = (probs_rf >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 3: Random Forest (umbral fijo 0.5)\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_rf, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_rf, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_rf, average=\"weighted\"))\n",
    "print(\"\\nM茅tricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "621f08d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrando umbrales para Random Forest...\n",
      "\n",
      "============================================================\n",
      "MODELO 3: Random Forest CON calibraci贸n de umbrales\n",
      "============================================================\n",
      "micro-F1: 0.5444832545716047\n",
      "macro-F1: 0.47330195719224744\n",
      "weighted-F1: 0.5649687243743775\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.06721698113207547, 'f1': 0.47330195719224744, 'precision': 0.4553511035206816, 'recall': 0.5525472162644545, 'hamming_loss': 0.1452437106918239}\n",
      "\n",
      "============================================================\n",
      "MODELO 3: Random Forest CON calibraci贸n de umbrales\n",
      "============================================================\n",
      "micro-F1: 0.5444832545716047\n",
      "macro-F1: 0.47330195719224744\n",
      "weighted-F1: 0.5649687243743775\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.06721698113207547, 'f1': 0.47330195719224744, 'precision': 0.4553511035206816, 'recall': 0.5525472162644545, 'hamming_loss': 0.1452437106918239}\n"
     ]
    }
   ],
   "source": [
    "# Calibrar umbrales para Random Forest\n",
    "print(\"Calibrando umbrales para Random Forest...\")\n",
    "probs_rf_train = clf_rf.predict_proba(XTR)\n",
    "ths_rf = np.zeros(probs_rf_train.shape[1])\n",
    "\n",
    "for k in range(probs_rf_train.shape[1]):\n",
    "    s = probs_rf_train[:, k]\n",
    "    best_f1, best_t = 0.0, 0.5\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1_tmp = f1_score(y_tr[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1_tmp > best_f1:\n",
    "            best_f1, best_t = f1_tmp, t\n",
    "    ths_rf[k] = best_t\n",
    "\n",
    "# Predicciones con umbrales calibrados\n",
    "pred_rf_cal = (probs_rf >= ths_rf).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 3: Random Forest CON calibraci贸n de umbrales\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_rf_cal, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_rf_cal, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_rf_cal, average=\"weighted\"))\n",
    "print(\"\\nM茅tricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_rf_cal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30956fcb",
   "metadata": {},
   "source": [
    "### **Resumen Comparativo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee5c313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESUMEN COMPARATIVO DE MODELOS\n",
      "================================================================================\n",
      "Modelo                                  Micro-F1     Macro-F1  Weighted-F1\n",
      "--------------------------------------------------------------------------------\n",
      "Logistic Regression + calibraci贸n         0.6334       0.5551       0.6459\n",
      "Naive Bayes (umbral 0.5)                  0.6140       0.4435       0.5934\n",
      "Naive Bayes + calibraci贸n                 0.6016       0.4984       0.5989\n",
      "Random Forest (umbral 0.5)                0.2544       0.1173       0.2166\n",
      "Random Forest + calibraci贸n               0.5445       0.4733       0.5650\n",
      "================================================================================\n",
      "\n",
      "Mejor modelo por Micro-F1:\n",
      "                              Modelo  Micro-F1  Macro-F1  Weighted-F1\n",
      "0  Logistic Regression + calibraci贸n  0.633359  0.555072     0.645859\n"
     ]
    }
   ],
   "source": [
    "# Crear tabla comparativa\n",
    "results = []\n",
    "\n",
    "models = [\n",
    "    (\"Logistic Regression + calibraci贸n\", pred),\n",
    "    (\"Naive Bayes (umbral 0.5)\", pred_nb),\n",
    "    (\"Naive Bayes + calibraci贸n\", pred_nb_cal),\n",
    "    (\"Random Forest (umbral 0.5)\", pred_rf),\n",
    "    (\"Random Forest + calibraci贸n\", pred_rf_cal)\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESUMEN COMPARATIVO DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Modelo':<35} {'Micro-F1':>12} {'Macro-F1':>12} {'Weighted-F1':>12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for name, predictions in models:\n",
    "    micro = f1_score(y_va, predictions, average=\"micro\")\n",
    "    macro = f1_score(y_va, predictions, average=\"macro\")\n",
    "    weighted = f1_score(y_va, predictions, average=\"weighted\")\n",
    "    print(f\"{name:<35} {micro:>12.4f} {macro:>12.4f} {weighted:>12.4f}\")\n",
    "    results.append({\n",
    "        'Modelo': name,\n",
    "        'Micro-F1': micro,\n",
    "        'Macro-F1': macro,\n",
    "        'Weighted-F1': weighted\n",
    "    })\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear DataFrame para mejor visualizaci贸n\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values('Micro-F1', ascending=False)\n",
    "print(\"\\nMejor modelo por Micro-F1:\")\n",
    "print(df_results.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ef371",
   "metadata": {},
   "source": [
    "## **Comparaci贸n con CountVectorizer**\n",
    "\n",
    "Ahora vamos a probar los mismos modelos pero usando **CountVectorizer** en lugar de TF-IDF para ver si hay diferencias en el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc61efb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando con CountVectorizer...\n",
      "Shape: (7627, 77705)\n",
      "Shape: (7627, 77705)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# --- CountVectorizer word + char ---\n",
    "count_word = CountVectorizer(\n",
    "    ngram_range=(1,2), min_df=3, max_features=300_000, stop_words=\"english\"\n",
    ")\n",
    "count_char = CountVectorizer(\n",
    "    analyzer=\"char_wb\", ngram_range=(3,5), min_df=3, max_features=300_000\n",
    ")\n",
    "\n",
    "print(\"Transformando con CountVectorizer...\")\n",
    "Xw_tr_count = count_word.fit_transform(X_tr);  Xw_va_count = count_word.transform(X_va)\n",
    "Xc_tr_count = count_char.fit_transform(X_tr);  Xc_va_count = count_char.transform(X_va)\n",
    "\n",
    "# Combinar word + char\n",
    "XTR_count = sp_hstack([Xw_tr_count, Xc_tr_count], format=\"csr\")\n",
    "XVA_count = sp_hstack([Xw_va_count, Xc_va_count], format=\"csr\")\n",
    "\n",
    "print(f\"Shape: {XTR_count.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d761c7",
   "metadata": {},
   "source": [
    "### **Modelo 1: Logistic Regression con CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a419216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Logistic Regression con CountVectorizer...\n",
      "\n",
      "============================================================\n",
      "Logistic Regression + CountVectorizer + calibraci贸n\n",
      "============================================================\n",
      "micro-F1: 0.5911634188693806\n",
      "macro-F1: 0.5084452569620344\n",
      "weighted-F1: 0.5947186263714275\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.08254716981132075, 'f1': 0.5084452569620344, 'precision': 0.46659793173969966, 'recall': 0.587063405690667, 'hamming_loss': 0.13882337526205452}\n",
      "\n",
      "============================================================\n",
      "Logistic Regression + CountVectorizer + calibraci贸n\n",
      "============================================================\n",
      "micro-F1: 0.5911634188693806\n",
      "macro-F1: 0.5084452569620344\n",
      "weighted-F1: 0.5947186263714275\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.08254716981132075, 'f1': 0.5084452569620344, 'precision': 0.46659793173969966, 'recall': 0.587063405690667, 'hamming_loss': 0.13882337526205452}\n"
     ]
    }
   ],
   "source": [
    "# Entrenar Logistic Regression con CountVectorizer\n",
    "clf_lr_count = OneVsRestClassifier(\n",
    "    LogisticRegression(C=4.0, solver=\"saga\", max_iter=2000, n_jobs=-1),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando Logistic Regression con CountVectorizer...\")\n",
    "clf_lr_count.fit(XTR_count, y_tr)\n",
    "\n",
    "# Calibraci贸n de umbrales\n",
    "logits_count = clf_lr_count.decision_function(XVA_count)\n",
    "ths_lr_count = np.zeros(logits_count.shape[1])\n",
    "\n",
    "for k in range(logits_count.shape[1]):\n",
    "    s = logits_count[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1_tmp = f1_score(y_va[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1_tmp > best_f1:\n",
    "            best_f1, best_t = f1_tmp, t\n",
    "    ths_lr_count[k] = best_t\n",
    "\n",
    "pred_lr_count = (logits_count >= ths_lr_count).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Logistic Regression + CountVectorizer + calibraci贸n\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_lr_count, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_lr_count, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_lr_count, average=\"weighted\"))\n",
    "print(\"\\nM茅tricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_lr_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fff470",
   "metadata": {},
   "source": [
    "### **Modelo 2: Naive Bayes con CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27a4683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Naive Bayes con CountVectorizer...\n",
      "\n",
      "============================================================\n",
      "Naive Bayes + CountVectorizer + calibraci贸n\n",
      "============================================================\n",
      "micro-F1: 0.6006148025537952\n",
      "macro-F1: 0.5039395423835606\n",
      "weighted-F1: 0.6010710781338638\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.1403301886792453, 'f1': 0.5039395423835606, 'precision': 0.5736236925916347, 'recall': 0.48357022889873424, 'hamming_loss': 0.11065251572327044}\n",
      "\n",
      "============================================================\n",
      "Naive Bayes + CountVectorizer + calibraci贸n\n",
      "============================================================\n",
      "micro-F1: 0.6006148025537952\n",
      "macro-F1: 0.5039395423835606\n",
      "weighted-F1: 0.6010710781338638\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.1403301886792453, 'f1': 0.5039395423835606, 'precision': 0.5736236925916347, 'recall': 0.48357022889873424, 'hamming_loss': 0.11065251572327044}\n"
     ]
    }
   ],
   "source": [
    "# Entrenar Naive Bayes con CountVectorizer\n",
    "clf_nb_count = OneVsRestClassifier(\n",
    "    MultinomialNB(alpha=0.1),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando Naive Bayes con CountVectorizer...\")\n",
    "clf_nb_count.fit(XTR_count, y_tr)\n",
    "\n",
    "# Calibraci贸n de umbrales\n",
    "probs_nb_count = clf_nb_count.predict_proba(XVA_count)\n",
    "probs_nb_count_train = clf_nb_count.predict_proba(XTR_count)\n",
    "ths_nb_count = np.zeros(probs_nb_count_train.shape[1])\n",
    "\n",
    "for k in range(probs_nb_count_train.shape[1]):\n",
    "    s = probs_nb_count_train[:, k]\n",
    "    best_f1, best_t = 0.0, 0.5\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1_tmp = f1_score(y_tr[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1_tmp > best_f1:\n",
    "            best_f1, best_t = f1_tmp, t\n",
    "    ths_nb_count[k] = best_t\n",
    "\n",
    "pred_nb_count = (probs_nb_count >= ths_nb_count).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Naive Bayes + CountVectorizer + calibraci贸n\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_nb_count, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_nb_count, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_nb_count, average=\"weighted\"))\n",
    "print(\"\\nM茅tricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_nb_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196213c5",
   "metadata": {},
   "source": [
    "### **Modelo 3: Random Forest con CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4aca3ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Random Forest con CountVectorizer (esto puede tardar un poco)...\n",
      "\n",
      "============================================================\n",
      "Random Forest + CountVectorizer + calibraci贸n\n",
      "============================================================\n",
      "micro-F1: 0.5626009693053312\n",
      "macro-F1: 0.47467920256782326\n",
      "weighted-F1: 0.5740550901842221\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.09080188679245282, 'f1': 0.47467920256782326, 'precision': 0.44896292823722495, 'recall': 0.5415173911309075, 'hamming_loss': 0.14190251572327045}\n",
      "\n",
      "============================================================\n",
      "Random Forest + CountVectorizer + calibraci贸n\n",
      "============================================================\n",
      "micro-F1: 0.5626009693053312\n",
      "macro-F1: 0.47467920256782326\n",
      "weighted-F1: 0.5740550901842221\n",
      "\n",
      "M茅tricas detalladas:\n",
      "{'accuracy': 0.09080188679245282, 'f1': 0.47467920256782326, 'precision': 0.44896292823722495, 'recall': 0.5415173911309075, 'hamming_loss': 0.14190251572327045}\n"
     ]
    }
   ],
   "source": [
    "# Entrenar Random Forest con CountVectorizer\n",
    "clf_rf_count = OneVsRestClassifier(\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=20, n_jobs=-1, random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando Random Forest con CountVectorizer (esto puede tardar un poco)...\")\n",
    "clf_rf_count.fit(XTR_count, y_tr)\n",
    "\n",
    "# Calibraci贸n de umbrales\n",
    "probs_rf_count = clf_rf_count.predict_proba(XVA_count)\n",
    "probs_rf_count_train = clf_rf_count.predict_proba(XTR_count)\n",
    "ths_rf_count = np.zeros(probs_rf_count_train.shape[1])\n",
    "\n",
    "for k in range(probs_rf_count_train.shape[1]):\n",
    "    s = probs_rf_count_train[:, k]\n",
    "    best_f1, best_t = 0.0, 0.5\n",
    "    for t in np.quantile(s, np.linspace(0.05, 0.95, 19)):\n",
    "        f1_tmp = f1_score(y_tr[:, k], (s >= t).astype(int), zero_division=0)\n",
    "        if f1_tmp > best_f1:\n",
    "            best_f1, best_t = f1_tmp, t\n",
    "    ths_rf_count[k] = best_t\n",
    "\n",
    "pred_rf_count = (probs_rf_count >= ths_rf_count).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Random Forest + CountVectorizer + calibraci贸n\")\n",
    "print(\"=\"*60)\n",
    "print(\"micro-F1:\", f1_score(y_va, pred_rf_count, average=\"micro\"))\n",
    "print(\"macro-F1:\", f1_score(y_va, pred_rf_count, average=\"macro\"))\n",
    "print(\"weighted-F1:\", f1_score(y_va, pred_rf_count, average=\"weighted\"))\n",
    "print(\"\\nM茅tricas detalladas:\")\n",
    "print(compute_metrics(y_va, pred_rf_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545a573",
   "metadata": {},
   "source": [
    "### **Resumen Comparativo: TF-IDF vs CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78107cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "COMPARACIN COMPLETA: TF-IDF vs CountVectorizer\n",
      "=====================================================================================\n",
      "Modelo                                            Micro-F1     Macro-F1  Weighted-F1\n",
      "-------------------------------------------------------------------------------------\n",
      "TF-IDF: Logistic Regression + calibraci贸n           0.6334       0.5551       0.6459\n",
      "TF-IDF: Naive Bayes (umbral 0.5)                    0.6140       0.4435       0.5934\n",
      "TF-IDF: Naive Bayes + calibraci贸n                   0.6016       0.4984       0.5989\n",
      "TF-IDF: Random Forest (umbral 0.5)                  0.2544       0.1173       0.2166\n",
      "TF-IDF: Random Forest + calibraci贸n                 0.5445       0.4733       0.5650\n",
      "Count: Logistic Regression + calibraci贸n            0.5912       0.5084       0.5947\n",
      "Count: Naive Bayes + calibraci贸n                    0.6006       0.5039       0.6011\n",
      "Count: Random Forest + calibraci贸n                  0.5626       0.4747       0.5741\n",
      "=====================================================================================\n",
      "\n",
      " TOP 3 MODELOS (por Micro-F1):\n",
      "                                   Modelo  Micro-F1  Macro-F1  Weighted-F1\n",
      "TF-IDF: Logistic Regression + calibraci贸n  0.633359  0.555072     0.645859\n",
      "         TF-IDF: Naive Bayes (umbral 0.5)  0.613997  0.443536     0.593404\n",
      "        TF-IDF: Naive Bayes + calibraci贸n  0.601572  0.498430     0.598929\n",
      "\n",
      " Comparaci贸n por vectorizador:\n",
      "Promedio TF-IDF: 0.5296\n",
      "Promedio CountVectorizer: 0.5848\n"
     ]
    }
   ],
   "source": [
    "# Comparaci贸n completa: TF-IDF vs CountVectorizer\n",
    "all_models = [\n",
    "    # TF-IDF\n",
    "    (\"TF-IDF: Logistic Regression + calibraci贸n\", pred),\n",
    "    (\"TF-IDF: Naive Bayes (umbral 0.5)\", pred_nb),\n",
    "    (\"TF-IDF: Naive Bayes + calibraci贸n\", pred_nb_cal),\n",
    "    (\"TF-IDF: Random Forest (umbral 0.5)\", pred_rf),\n",
    "    (\"TF-IDF: Random Forest + calibraci贸n\", pred_rf_cal),\n",
    "    # CountVectorizer\n",
    "    (\"Count: Logistic Regression + calibraci贸n\", pred_lr_count),\n",
    "    (\"Count: Naive Bayes + calibraci贸n\", pred_nb_count),\n",
    "    (\"Count: Random Forest + calibraci贸n\", pred_rf_count),\n",
    "]\n",
    "\n",
    "print(\"=\"*85)\n",
    "print(\"COMPARACIN COMPLETA: TF-IDF vs CountVectorizer\")\n",
    "print(\"=\"*85)\n",
    "print(f\"{'Modelo':<45} {'Micro-F1':>12} {'Macro-F1':>12} {'Weighted-F1':>12}\")\n",
    "print(\"-\"*85)\n",
    "\n",
    "all_results = []\n",
    "for name, predictions in all_models:\n",
    "    micro = f1_score(y_va, predictions, average=\"micro\")\n",
    "    macro = f1_score(y_va, predictions, average=\"macro\")\n",
    "    weighted = f1_score(y_va, predictions, average=\"weighted\")\n",
    "    print(f\"{name:<45} {micro:>12.4f} {macro:>12.4f} {weighted:>12.4f}\")\n",
    "    all_results.append({\n",
    "        'Modelo': name,\n",
    "        'Micro-F1': micro,\n",
    "        'Macro-F1': macro,\n",
    "        'Weighted-F1': weighted\n",
    "    })\n",
    "\n",
    "print(\"=\"*85)\n",
    "\n",
    "# Crear DataFrame ordenado por Micro-F1\n",
    "df_all_results = pd.DataFrame(all_results)\n",
    "df_all_results = df_all_results.sort_values('Micro-F1', ascending=False)\n",
    "\n",
    "print(\"\\n TOP 3 MODELOS (por Micro-F1):\")\n",
    "print(df_all_results.head(3).to_string(index=False))\n",
    "\n",
    "print(\"\\n Comparaci贸n por vectorizador:\")\n",
    "tfidf_avg = df_all_results[df_all_results['Modelo'].str.contains('TF-IDF')]['Micro-F1'].mean()\n",
    "count_avg = df_all_results[df_all_results['Modelo'].str.contains('Count')]['Micro-F1'].mean()\n",
    "print(f\"Promedio TF-IDF: {tfidf_avg:.4f}\")\n",
    "print(f\"Promedio CountVectorizer: {count_avg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
