{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f02983d",
   "metadata": {},
   "source": [
    "# Ensemble Optimizado para Predicci√≥n de G√©neros\n",
    "\n",
    "Este notebook implementa un ensemble avanzado con:\n",
    "- Data augmentation (back-translation)\n",
    "- DeBERTa-v3 (modelo top del leaderboard)\n",
    "- Optimizaci√≥n de pesos con Optuna\n",
    "- Test-time augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589b7590",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è VERIFICACI√ìN DE DATA LEAKAGE - CHECKLIST ‚úì\n",
    "\n",
    "**Puntos cr√≠ticos verificados:**\n",
    "1. ‚úÖ Data Augmentation SOLO en train (35%), validaci√≥n intacta\n",
    "2. ‚úÖ Train/Val split ANTES de augmentation\n",
    "3. ‚úÖ TF-IDF fit en train, transform en validation/test\n",
    "4. ‚úÖ BGE embeddings generados independientemente (no leakage)\n",
    "5. ‚úÖ SVC Calibration con cv=3 en TRAIN, no usa validation\n",
    "6. ‚úÖ Transformers (DistilBERT/DeBERTa) entrenados en train, evaluados en val\n",
    "7. ‚úÖ Thresholds optimizados en validation (correcto, es parte del modelo)\n",
    "8. ‚úÖ Optuna optimiza weights en validation (correcto)\n",
    "9. ‚ö†Ô∏è Stacking meta-model entrenado en validation (ligero overfitting, por eso usamos Weighted)\n",
    "10. ‚úÖ Test predictions NO usan augmentation\n",
    "11. ‚úÖ Todas las m√©tricas calculadas con validator.py\n",
    "\n",
    "**Archivo final a enviar:** `dataset_test_preds.csv` (Weighted Ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770b8d4",
   "metadata": {},
   "source": [
    "## 1. Imports y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ad285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.sparse import hstack as sp_hstack, csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, DistilBertForSequenceClassification,\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    Trainer, TrainingArguments,\n",
    "    MarianMTModel, MarianTokenizer\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar funci√≥n de validaci√≥n\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from validator import compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7131b8",
   "metadata": {},
   "source": [
    "## 2. Carga y Preparaci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3a087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 8475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silent Hill</td>\n",
       "      <td>Horror, Mystery</td>\n",
       "      <td>Rose, a desperate mother takes her adopted dau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breaking the Waves</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>In a small and conservative Scottish village, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wind Chill</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>Two college students share a ride home for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Godmothered</td>\n",
       "      <td>Family, Fantasy, Comedy</td>\n",
       "      <td>A young and unskilled fairy godmother that ven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donkey Skin</td>\n",
       "      <td>Fantasy, Comedy, Music, Romance</td>\n",
       "      <td>A fairy godmother helps a princess disguise he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_name                            genre  \\\n",
       "0         Silent Hill                  Horror, Mystery   \n",
       "1  Breaking the Waves                   Drama, Romance   \n",
       "2          Wind Chill          Drama, Horror, Thriller   \n",
       "3         Godmothered          Family, Fantasy, Comedy   \n",
       "4         Donkey Skin  Fantasy, Comedy, Music, Romance   \n",
       "\n",
       "                                         description  \n",
       "0  Rose, a desperate mother takes her adopted dau...  \n",
       "1  In a small and conservative Scottish village, ...  \n",
       "2  Two college students share a ride home for the...  \n",
       "3  A young and unskilled fairy godmother that ven...  \n",
       "4  A fairy godmother helps a princess disguise he...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = Path(\"../dataset_train.csv\")\n",
    "test_dir = Path(\"../dataset_test.csv\")\n",
    "\n",
    "df = pd.read_csv(train_dir)\n",
    "print(f\"Dataset size: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9e662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 18\n",
      "Label distribution shape: (8475, 18)\n"
     ]
    }
   ],
   "source": [
    "df[\"text\"] = df[\"movie_name\"].fillna(\"\") + \" [SEP] \" + df[\"description\"].fillna(\"\")\n",
    "y_list = df[\"genre\"].apply(lambda s: [g.strip() for g in str(s).split(\",\") if g.strip()])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(y_list)\n",
    "\n",
    "print(f\"Number of labels: {len(mlb.classes_)}\")\n",
    "print(f\"Label distribution shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b339d",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation - Back Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfac7b3",
   "metadata": {},
   "source": [
    "### ‚ö° Optimizaciones de Velocidad\n",
    "\n",
    "**Back-translation optimizado seg√∫n hardware:**\n",
    "\n",
    "**üöÄ MODO GPU** (si est√° disponible):\n",
    "- Procesamiento por **BATCHES** (no workers - la GPU ya paraleliza internamente)\n",
    "- `batch_size=16`: Procesa 16 textos simult√°neamente en GPU\n",
    "- Batch m√°s grande = m√°s r√°pido, pero m√°s VRAM\n",
    "- Velocidad: **~20-50x m√°s r√°pido que CPU**\n",
    "\n",
    "**\udcbb MODO CPU** (fallback autom√°tico):\n",
    "- Procesamiento con **THREADING** (m√∫ltiples workers)\n",
    "- `batch_size=4`: N√∫mero de workers paralelos\n",
    "- M√°s workers = m√°s r√°pido, pero m√°s RAM/cores\n",
    "- Velocidad: **~3-4x m√°s r√°pido que secuencial**\n",
    "\n",
    "**Configuraci√≥n recomendada:**\n",
    "```python\n",
    "# GPU con 4-8GB VRAM\n",
    "batch_size=16  # √ìptimo\n",
    "\n",
    "# GPU con 12+ GB VRAM  \n",
    "batch_size=32  # Muy r√°pido\n",
    "\n",
    "# CPU (4-8 cores)\n",
    "batch_size=4  # workers paralelos\n",
    "```\n",
    "\n",
    "**Tiempos estimados** (1,560 traducciones):\n",
    "- CPU secuencial: ~25-35 min\n",
    "- CPU paralelo (4 workers): ~8-10 min  \n",
    "- **GPU batch=16**: **~1-2 min** ‚ö°üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223eb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "def back_translate(texts, src_lang='en', pivot_lang='fr', sample_ratio=0.2, batch_size=16, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Back-translation optimizado con GPU (batching) o CPU (threading).\n",
    "    \n",
    "    Args:\n",
    "        texts: Textos a augmentar\n",
    "        src_lang: Idioma origen (default: 'en')\n",
    "        pivot_lang: Idioma pivot (default: 'fr')\n",
    "        sample_ratio: Porcentaje de textos a augmentar\n",
    "        batch_size: Tama√±o de batch para GPU (default: 16), o workers para CPU\n",
    "        use_gpu: Usar GPU si est√° disponible (default: True)\n",
    "    \"\"\"\n",
    "    model_name_en_pivot = f'Helsinki-NLP/opus-mt-{src_lang}-{pivot_lang}'\n",
    "    model_name_pivot_en = f'Helsinki-NLP/opus-mt-{pivot_lang}-{src_lang}'\n",
    "    \n",
    "    # Detectar dispositivo\n",
    "    device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Cargar modelos una sola vez\n",
    "    tokenizer_en_pivot = MarianTokenizer.from_pretrained(model_name_en_pivot)\n",
    "    model_en_pivot = MarianMTModel.from_pretrained(model_name_en_pivot).to(device)\n",
    "    model_en_pivot.eval()  # Modo evaluaci√≥n para inference\n",
    "    \n",
    "    tokenizer_pivot_en = MarianTokenizer.from_pretrained(model_name_pivot_en)\n",
    "    model_pivot_en = MarianMTModel.from_pretrained(model_name_pivot_en).to(device)\n",
    "    model_pivot_en.eval()\n",
    "    \n",
    "    # Seleccionar √≠ndices a augmentar\n",
    "    indices_to_augment = np.random.choice(len(texts), size=int(len(texts) * sample_ratio), replace=False)\n",
    "    texts_to_augment = [texts.iloc[idx] if hasattr(texts, 'iloc') else texts[idx] for idx in indices_to_augment]\n",
    "    total = len(texts_to_augment)\n",
    "    \n",
    "    augmented_texts = []\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        # ===== MODO GPU: Procesamiento por BATCHES (m√°s eficiente) =====\n",
    "        print(f\"GPU mode: Processing in batches of {batch_size}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, total, batch_size):\n",
    "                batch_texts = texts_to_augment[i:i+batch_size]\n",
    "                \n",
    "                # EN -> Pivot (batch completo)\n",
    "                inputs = tokenizer_en_pivot(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                translated = model_en_pivot.generate(**inputs, max_length=128)\n",
    "                pivot_texts = [tokenizer_en_pivot.decode(t, skip_special_tokens=True) for t in translated]\n",
    "                \n",
    "                # Pivot -> EN (batch completo)\n",
    "                inputs = tokenizer_pivot_en(pivot_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                back_translated = model_pivot_en.generate(**inputs, max_length=128)\n",
    "                final_texts = [tokenizer_pivot_en.decode(t, skip_special_tokens=True) for t in back_translated]\n",
    "                \n",
    "                augmented_texts.extend(final_texts)\n",
    "                \n",
    "                # Progreso\n",
    "                if (i + batch_size) % (batch_size * 5) == 0 or (i + batch_size) >= total:\n",
    "                    print(f\"Augmenting {min(i + batch_size, total)}/{total}...\", end='\\r')\n",
    "        \n",
    "        print(f\"\\nGPU augmentation complete! ({len(augmented_texts)} texts)\" + \" \"*20)\n",
    "    \n",
    "    else:\n",
    "        # ===== MODO CPU: Procesamiento con THREADING (paralelizaci√≥n) =====\n",
    "        n_workers = batch_size  # Reusar par√°metro como n√∫mero de workers\n",
    "        print(f\"CPU mode: Processing with {n_workers} parallel workers\")\n",
    "        \n",
    "        counter = {'value': 0, 'lock': threading.Lock()}\n",
    "        \n",
    "        def translate_single(text):\n",
    "            \"\"\"Funci√≥n para traducir un texto individual en CPU\"\"\"\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    # EN -> Pivot\n",
    "                    inputs = tokenizer_en_pivot(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "                    translated = model_en_pivot.generate(**inputs)\n",
    "                    pivot_text = tokenizer_en_pivot.decode(translated[0], skip_special_tokens=True)\n",
    "                    \n",
    "                    # Pivot -> EN\n",
    "                    inputs = tokenizer_pivot_en(pivot_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "                    back_translated = model_pivot_en.generate(**inputs)\n",
    "                    final_text = tokenizer_pivot_en.decode(back_translated[0], skip_special_tokens=True)\n",
    "                \n",
    "                # Actualizar progreso\n",
    "                with counter['lock']:\n",
    "                    counter['value'] += 1\n",
    "                    if counter['value'] % 50 == 0 or counter['value'] == total:\n",
    "                        print(f\"Augmenting {counter['value']}/{total}...\", end='\\r')\n",
    "                \n",
    "                return final_text\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError translating text: {e}\")\n",
    "                return text\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "            augmented_texts = list(executor.map(translate_single, texts_to_augment))\n",
    "        \n",
    "        print(f\"\\nCPU augmentation complete! ({len(augmented_texts)} texts)\" + \" \"*20)\n",
    "    \n",
    "    return augmented_texts, indices_to_augment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 0/1695...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete!                    \n",
      "Augmentation complete!                    \n",
      "Augmented dataset size: 10170\n",
      "Training samples: 9153, Validation samples: 1017\n",
      "Augmented dataset size: 10170\n",
      "Training samples: 9153, Validation samples: 1017\n"
     ]
    }
   ],
   "source": [
    "# Split ANTES de augmentar - validaci√≥n con datos 100% originales\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(df[\"text\"], Y, test_size=0.1, random_state=42)\n",
    "print(f\"Original - Training: {len(X_tr)}, Validation: {len(X_va)}\")\n",
    "\n",
    "# Augmentar SOLO train con ratio aumentado\n",
    "# GPU: batch_size controla tama√±o de batch (16-32 √≥ptimo)\n",
    "# CPU: batch_size controla n√∫mero de workers (4-8 √≥ptimo)\n",
    "print(f\"\\nAugmenting training data...\")\n",
    "augmented_texts, aug_indices = back_translate(X_tr, sample_ratio=0.35, batch_size=16, use_gpu=True)\n",
    "\n",
    "# Obtener las etiquetas correspondientes a los √≠ndices augmentados\n",
    "y_tr_augmented = y_tr[aug_indices]\n",
    "\n",
    "# Combinar train original + train augmentado\n",
    "X_tr_combined = pd.concat([X_tr.reset_index(drop=True), pd.Series(augmented_texts)], ignore_index=True)\n",
    "y_tr_combined = np.vstack([y_tr, y_tr_augmented])\n",
    "\n",
    "print(f\"Augmented - Training: {len(X_tr_combined)}, Validation: {len(X_va)} (unchanged)\")\n",
    "print(f\"Train augmentation: +{len(augmented_texts)} samples ({len(augmented_texts)/len(X_tr):.1%})\")\n",
    "\n",
    "# Actualizar variables para uso posterior\n",
    "X_tr = X_tr_combined\n",
    "y_tr = y_tr_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "232fdd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3f7925a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_va_nvembed.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_tr, \"X_tr_nvembed.pkl\")\n",
    "joblib.dump(X_va, \"X_va_nvembed.pkl\")\n",
    "joblib.dump(y_tr, \"y_tr_nvembed.pkl\")\n",
    "joblib.dump(y_va, \"y_va_nvembed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2434d4e",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7b233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined TF-IDF features shape: (9153, 205446)\n"
     ]
    }
   ],
   "source": [
    "tfidf_word = TfidfVectorizer(\n",
    "    ngram_range=(1,4),\n",
    "    min_df=2,\n",
    "    max_features=750_000,\n",
    "    sublinear_tf=True,\n",
    "    stop_words=\"english\",\n",
    "    max_df=0.85,\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "tfidf_char = TfidfVectorizer(\n",
    "    analyzer=\"char_wb\",\n",
    "    ngram_range=(3,6),\n",
    "    min_df=2,\n",
    "    max_features=750_000,\n",
    "    sublinear_tf=True,\n",
    "    max_df=0.85,\n",
    "    strip_accents='unicode'\n",
    ")\n",
    "\n",
    "Xw_tr = tfidf_word.fit_transform(X_tr)\n",
    "Xw_va = tfidf_word.transform(X_va)\n",
    "Xc_tr = tfidf_char.fit_transform(X_tr)\n",
    "Xc_va = tfidf_char.transform(X_va)\n",
    "\n",
    "XTR_tfidf = sp_hstack([Xw_tr, Xc_tr], format=\"csr\")\n",
    "XVA_tfidf = sp_hstack([Xw_va, Xc_va], format=\"csr\")\n",
    "print(f\"Combined TF-IDF features shape: {XTR_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edec731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar TF-IDF vectorizers, MultiLabelBinarizer y labels\n",
    "joblib.dump(tfidf_word, \"tfidf_word.joblib\")\n",
    "joblib.dump(tfidf_char, \"tfidf_char.joblib\")\n",
    "joblib.dump(mlb, \"mlb.joblib\")\n",
    "\n",
    "# Guardar labels.json\n",
    "import json\n",
    "labels_dict = {\"labels\": mlb.classes_.tolist()}\n",
    "with open(\"labels.json\", \"w\") as f:\n",
    "    json.dump(labels_dict, f, indent=2)\n",
    "\n",
    "print(\"TF-IDF vectorizers, MLB and labels.json saved!\")\n",
    "print(f\"Number of labels: {len(mlb.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3769ce1",
   "metadata": {},
   "source": [
    "## 5. Embeddings Mejorados (BGE-Large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2148dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
    "print(\"Generating embeddings with BGE-Large (1024 dim)...\")\n",
    "emb_tr = st_model.encode(X_tr.tolist(), show_progress_bar=True, batch_size=16, normalize_embeddings=True)\n",
    "emb_va = st_model.encode(X_va.tolist(), show_progress_bar=True, batch_size=16, normalize_embeddings=True)\n",
    "\n",
    "XTR_combined = sp_hstack([XTR_tfidf, csr_matrix(emb_tr)], format=\"csr\")\n",
    "XVA_combined = sp_hstack([XVA_tfidf, csr_matrix(emb_va)], format=\"csr\")\n",
    "print(f\"Combined features (TF-IDF + BGE Embeddings) shape: {XTR_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar sentence transformer model\n",
    "joblib.dump(st_model, \"sentence_transformer.joblib\")\n",
    "print(\"Sentence Transformer model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d796aa",
   "metadata": {},
   "source": [
    "## 6. Calibraci√≥n y Modelos Mejorados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89b6db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression...\n",
      "LogReg training complete!\n",
      "LogReg training complete!\n"
     ]
    }
   ],
   "source": [
    "clf_logreg = OneVsRestClassifier(\n",
    "    LogisticRegression(C=8.0, solver=\"saga\", max_iter=4000, class_weight='balanced', random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(\"Training LogisticRegression...\")\n",
    "clf_logreg.fit(XTR_combined, y_tr)\n",
    "print(\"LogReg training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045bc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg - micro-F1: 0.7315, macro-F1: 0.6982\n"
     ]
    }
   ],
   "source": [
    "logits_logreg = clf_logreg.decision_function(XVA_combined)\n",
    "ths_logreg = np.zeros(logits_logreg.shape[1])\n",
    "\n",
    "for k in range(logits_logreg.shape[1]):\n",
    "    s = logits_logreg[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_logreg[k] = best_t\n",
    "\n",
    "pred_logreg = (logits_logreg >= ths_logreg).astype(int)\n",
    "metrics_logreg = compute_metrics(y_va, pred_logreg)\n",
    "print(f\"LogReg - F1: {metrics_logreg['f1']:.4f}, Precision: {metrics_logreg['precision']:.4f}, Recall: {metrics_logreg['recall']:.4f}, Hamming: {metrics_logreg['hamming_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8473c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo LogReg\n",
    "joblib.dump(clf_logreg, \"clf_logreg.joblib\")\n",
    "joblib.dump(ths_logreg, \"ths_logreg.npy\")\n",
    "print(\"LogReg model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a7c0a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "XGBoost training complete!\n",
      "XGBoost training complete!\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = MultiOutputClassifier(\n",
    "    XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
    ")\n",
    "print(\"Training XGBoost...\")\n",
    "clf_xgb.fit(emb_tr, y_tr)\n",
    "print(\"XGBoost training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ba68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - micro-F1: 0.6934, macro-F1: 0.6395\n"
     ]
    }
   ],
   "source": [
    "pred_proba_xgb = clf_xgb.predict_proba(emb_va)\n",
    "logits_xgb = np.column_stack([p[:, 1] for p in pred_proba_xgb])\n",
    "ths_xgb = np.zeros(logits_xgb.shape[1])\n",
    "\n",
    "for k in range(logits_xgb.shape[1]):\n",
    "    s = logits_xgb[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_xgb[k] = best_t\n",
    "\n",
    "pred_xgb = (logits_xgb >= ths_xgb).astype(int)\n",
    "metrics_xgb = compute_metrics(y_va, pred_xgb)\n",
    "print(f\"XGBoost - F1: {metrics_xgb['f1']:.4f}, Precision: {metrics_xgb['precision']:.4f}, Recall: {metrics_xgb['recall']:.4f}, Hamming: {metrics_xgb['hamming_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa13fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo XGBoost\n",
    "joblib.dump(clf_xgb, \"clf_xgb.joblib\")\n",
    "joblib.dump(ths_xgb, \"ths_xgb.npy\")\n",
    "print(\"XGBoost model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f5c496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinearSVC...\n",
      "SVC training complete!\n",
      "SVC training complete!\n"
     ]
    }
   ],
   "source": [
    "clf_svc = OneVsRestClassifier(\n",
    "    LinearSVC(C=2.0, max_iter=4000, class_weight='balanced', dual='auto', random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(\"Training LinearSVC...\")\n",
    "clf_svc.fit(XTR_tfidf, y_tr)\n",
    "print(\"SVC training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554fc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC - micro-F1: 0.7258, macro-F1: 0.7030\n"
     ]
    }
   ],
   "source": [
    "logits_svc = clf_svc.decision_function(XVA_tfidf)\n",
    "ths_svc = np.zeros(logits_svc.shape[1])\n",
    "\n",
    "for k in range(logits_svc.shape[1]):\n",
    "    s = logits_svc[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_svc[k] = best_t\n",
    "\n",
    "pred_svc = (logits_svc >= ths_svc).astype(int)\n",
    "metrics_svc = compute_metrics(y_va, pred_svc)\n",
    "print(f\"LinearSVC - F1: {metrics_svc['f1']:.4f}, Precision: {metrics_svc['precision']:.4f}, Recall: {metrics_svc['recall']:.4f}, Hamming: {metrics_svc['hamming_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo SVC\n",
    "joblib.dump(clf_svc, \"clf_svc.joblib\")\n",
    "joblib.dump(ths_svc, \"ths_svc.npy\")\n",
    "print(\"SVC model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc6674",
   "metadata": {},
   "source": [
    "## Calibraci√≥n Probabil√≠stica SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf27e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "print(\"Calibrating SVC probabilities with cross-validation on TRAIN...\")\n",
    "# IMPORTANTE: Para multi-label, calibramos cada clasificador binario individualmente\n",
    "# CalibratedClassifierCV no funciona bien directamente con OneVsRestClassifier multi-label\n",
    "\n",
    "# Entrenar SVC base primero\n",
    "base_svc = OneVsRestClassifier(\n",
    "    LinearSVC(C=2.0, max_iter=4000, class_weight='balanced', dual='auto', random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "base_svc.fit(XTR_tfidf, y_tr)\n",
    "\n",
    "# Calibrar cada clasificador binario individualmente\n",
    "n_labels = y_tr.shape[1]\n",
    "calibrated_classifiers = []\n",
    "\n",
    "for i in range(n_labels):\n",
    "    # Calibrar cada clasificador binario con cv=3\n",
    "    clf_calibrated = CalibratedClassifierCV(\n",
    "        LinearSVC(C=2.0, max_iter=4000, class_weight='balanced', dual='auto', random_state=42),\n",
    "        cv=3,\n",
    "        method='sigmoid'\n",
    "    )\n",
    "    clf_calibrated.fit(XTR_tfidf, y_tr[:, i])\n",
    "    calibrated_classifiers.append(clf_calibrated)\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"Calibrated {i + 1}/{n_labels} classifiers...\", end='\\r')\n",
    "\n",
    "print(f\"\\nCalibrated all {n_labels} classifiers!\")\n",
    "\n",
    "# Obtener probabilidades calibradas en VALIDACI√ìN\n",
    "logits_svc_cal = np.zeros((XVA_tfidf.shape[0], n_labels))\n",
    "for i, clf in enumerate(calibrated_classifiers):\n",
    "    logits_svc_cal[:, i] = clf.predict_proba(XVA_tfidf)[:, 1]\n",
    "\n",
    "# Optimizar thresholds con calibraci√≥n\n",
    "ths_svc_cal = np.zeros(n_labels)\n",
    "for k in range(n_labels):\n",
    "    s = logits_svc_cal[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_svc_cal[k] = best_t\n",
    "\n",
    "pred_svc_cal = (logits_svc_cal >= ths_svc_cal).astype(int)\n",
    "metrics_svc_cal = compute_metrics(y_va, pred_svc_cal)\n",
    "print(f\"Calibrated SVC - F1: {metrics_svc_cal['f1']:.4f}, Precision: {metrics_svc_cal['precision']:.4f}, Recall: {metrics_svc_cal['recall']:.4f}, Hamming: {metrics_svc_cal['hamming_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelos SVC calibrados (lista de clasificadores binarios)\n",
    "joblib.dump(calibrated_classifiers, \"clf_svc_calibrated_list.joblib\")\n",
    "joblib.dump(ths_svc_cal, \"ths_svc_cal.npy\")\n",
    "print(\"Calibrated SVC models saved (list of binary classifiers)!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccf671",
   "metadata": {},
   "source": [
    "## 7. DistilBERT con Focal Loss y Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a585825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss_fct = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "print(\"Focal Loss class defined for DistilBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cb91495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGenreDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx]) if hasattr(self.texts, 'iloc') else str(self.texts[idx])\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5a3def6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created: 9153 training, 1017 validation\n"
     ]
    }
   ],
   "source": [
    "tokenizer_distilbert = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model_distilbert = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=len(mlb.classes_),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "train_dataset_distilbert = MovieGenreDataset(X_tr, y_tr, tokenizer_distilbert, max_length=128)\n",
    "val_dataset_distilbert = MovieGenreDataset(X_va, y_va, tokenizer_distilbert, max_length=128)\n",
    "print(f\"Datasets created: {len(train_dataset_distilbert)} training, {len(val_dataset_distilbert)} validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DistilBERT...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1719' max='1719' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1719/1719 59:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.261026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.209570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.203075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT training complete!\n"
     ]
    }
   ],
   "source": [
    "training_args_distilbert = TrainingArguments(\n",
    "    output_dir='./distilbert_results',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    label_smoothing_factor=0.1,\n",
    ")\n",
    "\n",
    "trainer_distilbert = CustomTrainer(\n",
    "    model=model_distilbert,\n",
    "    args=training_args_distilbert,\n",
    "    train_dataset=train_dataset_distilbert,\n",
    "    eval_dataset=val_dataset_distilbert,\n",
    ")\n",
    "\n",
    "print(\"Training DistilBERT with Focal Loss + Label Smoothing...\")\n",
    "trainer_distilbert.train()\n",
    "print(\"DistilBERT training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d9aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT - micro-F1: 0.7234, macro-F1: 0.6736\n"
     ]
    }
   ],
   "source": [
    "model_distilbert.eval()\n",
    "with torch.no_grad():\n",
    "    val_inputs = tokenizer_distilbert(X_va.tolist(), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "    outputs = model_distilbert(**val_inputs)\n",
    "    logits_distilbert = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "\n",
    "ths_distilbert = np.zeros(logits_distilbert.shape[1])\n",
    "for k in range(logits_distilbert.shape[1]):\n",
    "    s = logits_distilbert[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_distilbert[k] = best_t\n",
    "\n",
    "pred_distilbert = (logits_distilbert >= ths_distilbert).astype(int)\n",
    "metrics_distilbert = compute_metrics(y_va, pred_distilbert)\n",
    "print(f\"DistilBERT - F1: {metrics_distilbert['f1']:.4f}, Precision: {metrics_distilbert['precision']:.4f}, Recall: {metrics_distilbert['recall']:.4f}, Hamming: {metrics_distilbert['hamming_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo DistilBERT\n",
    "model_distilbert.save_pretrained(\"./distilbert_model\")\n",
    "tokenizer_distilbert.save_pretrained(\"./distilbert_model\")\n",
    "np.save(\"ths_distilbert.npy\", ths_distilbert)\n",
    "print(\"DistilBERT model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e182905",
   "metadata": {},
   "source": [
    "## 8. DeBERTa-v3 (Top Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53240274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeBERTa datasets created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "tokenizer_deberta = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "model_deberta = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-v3-base\",\n",
    "    num_labels=len(mlb.classes_),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "train_dataset_deberta = MovieGenreDataset(X_tr, y_tr, tokenizer_deberta, max_length=256)\n",
    "val_dataset_deberta = MovieGenreDataset(X_va, y_va, tokenizer_deberta, max_length=256)\n",
    "print(f\"DeBERTa datasets created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37144ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DeBERTa-v3...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='694' max='2865' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 694/2865 2:14:03 < 7:00:34, 0.09 it/s, Epoch 1.21/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.279900</td>\n",
       "      <td>0.265815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     17\u001b[39m trainer_deberta = Trainer(\n\u001b[32m     18\u001b[39m     model=model_deberta,\n\u001b[32m     19\u001b[39m     args=training_args_deberta,\n\u001b[32m     20\u001b[39m     train_dataset=train_dataset_deberta,\n\u001b[32m     21\u001b[39m     eval_dataset=val_dataset_deberta,\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining DeBERTa-v3...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mtrainer_deberta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDeBERTa training complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:2715\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2713\u001b[39m         grad_norm_context = implicit_replication\n\u001b[32m   2714\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m grad_norm_context():\n\u001b[32m-> \u001b[39m\u001b[32m2715\u001b[39m         _grad_norm = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2716\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2717\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2718\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2721\u001b[39m     is_accelerate_available()\n\u001b[32m   2722\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED\n\u001b[32m   2723\u001b[39m ):\n\u001b[32m   2724\u001b[39m     grad_norm = model.get_global_grad_norm()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\accelerate\\accelerator.py:2897\u001b[39m, in \u001b[36mAccelerator.clip_grad_norm_\u001b[39m\u001b[34m(self, parameters, max_norm, norm_type)\u001b[39m\n\u001b[32m   2895\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m model.clip_grad_norm_(max_norm, norm_type)\n\u001b[32m   2896\u001b[39m \u001b[38;5;28mself\u001b[39m.unscale_gradients()\n\u001b[32m-> \u001b[39m\u001b[32m2897\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:43\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:232\u001b[39m, in \u001b[36mclip_grad_norm_\u001b[39m\u001b[34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m    230\u001b[39m grads = [p.grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    231\u001b[39m total_norm = _get_total_norm(grads, norm_type, error_if_nonfinite, foreach)\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[43m_clip_grads_with_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:43\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shiyi Cheng yi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:174\u001b[39m, in \u001b[36m_clip_grads_with_norm_\u001b[39m\u001b[34m(parameters, max_norm, total_norm, foreach)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (device, _), ([device_grads], _) \u001b[38;5;129;01min\u001b[39;00m grouped_grads.items():\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(device_grads, device)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    172\u001b[39m         foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device)\n\u001b[32m    173\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_coef_clamped\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[32m    176\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    177\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mforeach=True was passed, but can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice.type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m         )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "training_args_deberta = TrainingArguments(\n",
    "    output_dir='./deberta_results',\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    "    label_smoothing_factor=0.1,\n",
    ")\n",
    "\n",
    "trainer_deberta = CustomTrainer(\n",
    "    model=model_deberta,\n",
    "    args=training_args_deberta,\n",
    "    train_dataset=train_dataset_deberta,\n",
    "    eval_dataset=val_dataset_deberta,\n",
    ")\n",
    "\n",
    "print(\"Training DeBERTa-v3 with Focal Loss + Label Smoothing (8 epochs)...\")\n",
    "trainer_deberta.train()\n",
    "print(\"DeBERTa training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deberta.eval()\n",
    "with torch.no_grad():\n",
    "    val_inputs = tokenizer_deberta(X_va.tolist(), truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "    outputs = model_deberta(**val_inputs)\n",
    "    logits_deberta = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "\n",
    "ths_deberta = np.zeros(logits_deberta.shape[1])\n",
    "for k in range(logits_deberta.shape[1]):\n",
    "    s = logits_deberta[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_deberta[k] = best_t\n",
    "\n",
    "pred_deberta = (logits_deberta >= ths_deberta).astype(int)\n",
    "metrics_deberta = compute_metrics(y_va, pred_deberta)\n",
    "print(f\"DeBERTa-v3 - F1: {metrics_deberta['f1']:.4f}, Precision: {metrics_deberta['precision']:.4f}, Recall: {metrics_deberta['recall']:.4f}, Hamming: {metrics_deberta['hamming_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b14835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo DeBERTa\n",
    "model_deberta.save_pretrained(\"./deberta_model\")\n",
    "tokenizer_deberta.save_pretrained(\"./deberta_model\")\n",
    "np.save(\"ths_deberta.npy\", ths_deberta)\n",
    "print(\"DeBERTa model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ef5aa",
   "metadata": {},
   "source": [
    "## 9. Ensemble con Stacking (Meta-learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0132966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "# NOTA IMPORTANTE: Stacking ideal requiere predicciones out-of-fold de TODOS los modelos\n",
    "# Los transformers (DistilBERT/DeBERTa) no tienen OOF f√°cilmente disponible\n",
    "# Por simplicidad y evitar data leakage, usamos ensemble ponderado optimizado como principal\n",
    "# Guardamos el c√≥digo de stacking pero es OPCIONAL y puede tener ligero overfitting\n",
    "\n",
    "# Stack todos los logits de VALIDACI√ìN\n",
    "stacked_features_val = np.column_stack([\n",
    "    logits_deberta, \n",
    "    logits_distilbert, \n",
    "    logits_logreg, \n",
    "    logits_xgb, \n",
    "    logits_svc_cal\n",
    "])\n",
    "\n",
    "print(f\"Stacked features shape: {stacked_features_val.shape}\")\n",
    "\n",
    "# Meta-learner con Ridge Regression (regularizado para reducir overfitting)\n",
    "meta_model = OneVsRestClassifier(\n",
    "    RidgeClassifierCV(alphas=[0.1, 0.5, 1.0, 5.0, 10.0], cv=3),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training stacking meta-model...\")\n",
    "print(\"‚ö†Ô∏è  WARNING: Training on validation set (not ideal but validation is small)\")\n",
    "meta_model.fit(stacked_features_val, y_va)\n",
    "\n",
    "# Predicciones del meta-model\n",
    "pred_stacking = meta_model.predict(stacked_features_val)\n",
    "metrics_stacking = compute_metrics(y_va, pred_stacking)\n",
    "print(f\"Stacking Ensemble - F1: {metrics_stacking['f1']:.4f}, Precision: {metrics_stacking['precision']:.4f}, Recall: {metrics_stacking['recall']:.4f}, Hamming: {metrics_stacking['hamming_loss']:.4f}\")\n",
    "print(f\"‚ö†Ô∏è  These metrics may be optimistic - prefer Weighted Ensemble metrics for true performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6cf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar meta-model (opcional, prefer weighted ensemble)\n",
    "joblib.dump(meta_model, \"meta_model_stacking.joblib\")\n",
    "print(\"Stacking meta-model saved (use with caution - may be overfit)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d0441b",
   "metadata": {},
   "source": [
    "## 10. Optimizaci√≥n de Pesos con Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e523e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "def objective_with_hamming(trial):\n",
    "    w_deberta = trial.suggest_float(\"w_deberta\", 0.3, 0.6)\n",
    "    w_distilbert = trial.suggest_float(\"w_distilbert\", 0.1, 0.4)\n",
    "    w_logreg = trial.suggest_float(\"w_logreg\", 0.1, 0.3)\n",
    "    w_xgb = trial.suggest_float(\"w_xgb\", 0.05, 0.25)\n",
    "    w_svc = max(0.0, 1.0 - w_deberta - w_distilbert - w_logreg - w_xgb)\n",
    "    \n",
    "    ensemble_logits_opt = (w_deberta * logits_deberta + \n",
    "                           w_distilbert * logits_distilbert + \n",
    "                           w_logreg * logits_logreg + \n",
    "                           w_xgb * logits_xgb + \n",
    "                           w_svc * logits_svc_cal)\n",
    "    \n",
    "    # Optimizar thresholds\n",
    "    ths_opt = np.zeros(ensemble_logits_opt.shape[1])\n",
    "    for k in range(ensemble_logits_opt.shape[1]):\n",
    "        s = ensemble_logits_opt[:, k]\n",
    "        best_f1, best_t = 0.0, 0.0\n",
    "        candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "        for t in candidates:\n",
    "            preds_k = (s >= t).astype(int)\n",
    "            f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "        ths_opt[k] = best_t\n",
    "    \n",
    "    pred_opt = (ensemble_logits_opt >= ths_opt).astype(int)\n",
    "    \n",
    "    # Combinar F1 macro y Hamming Loss\n",
    "    f1_macro = f1_score(y_va, pred_opt, average='macro')\n",
    "    hamming = hamming_loss(y_va, pred_opt)\n",
    "    \n",
    "    return f1_macro - 0.3 * hamming\n",
    "\n",
    "print(\"Optimizing ensemble weights (F1 macro - Hamming Loss)...\")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_with_hamming, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest score (F1 - 0.3*Hamming): {study.best_value:.4f}\")\n",
    "print(\"Best weights:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da5fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "w_deberta_opt = best_params['w_deberta']\n",
    "w_distilbert_opt = best_params['w_distilbert']\n",
    "w_logreg_opt = best_params['w_logreg']\n",
    "w_xgb_opt = best_params['w_xgb']\n",
    "w_svc_opt = 1.0 - w_deberta_opt - w_distilbert_opt - w_logreg_opt - w_xgb_opt\n",
    "\n",
    "ensemble_optimized = (w_deberta_opt * logits_deberta + \n",
    "                      w_distilbert_opt * logits_distilbert + \n",
    "                      w_logreg_opt * logits_logreg + \n",
    "                      w_xgb_opt * logits_xgb + \n",
    "                      w_svc_opt * logits_svc_cal)\n",
    "\n",
    "# Optimizaci√≥n de thresholds con b√∫squeda m√°s precisa\n",
    "ths_optimized = np.zeros(ensemble_optimized.shape[1])\n",
    "for k in range(ensemble_optimized.shape[1]):\n",
    "    s = ensemble_optimized[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.unique(np.quantile(s, np.linspace(0, 1, 100)))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_optimized[k] = best_t\n",
    "\n",
    "# Ajuste para reducir Hamming Loss\n",
    "avg_labels_train = y_va.sum(axis=1).mean()\n",
    "for iteration in range(10):\n",
    "    pred_optimized = (ensemble_optimized >= ths_optimized).astype(int)\n",
    "    current_avg = pred_optimized.sum(axis=1).mean()\n",
    "    \n",
    "    if abs(current_avg - avg_labels_train) < 0.1:\n",
    "        break\n",
    "    \n",
    "    if current_avg > avg_labels_train:\n",
    "        ths_optimized *= 1.02\n",
    "    else:\n",
    "        ths_optimized *= 0.98\n",
    "\n",
    "pred_optimized = (ensemble_optimized >= ths_optimized).astype(int)\n",
    "metrics_optimized = compute_metrics(y_va, pred_optimized)\n",
    "print(f\"Optimized Ensemble - F1: {metrics_optimized['f1']:.4f}, Precision: {metrics_optimized['precision']:.4f}, Recall: {metrics_optimized['recall']:.4f}, Hamming: {metrics_optimized['hamming_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c5181",
   "metadata": {},
   "source": [
    "## 11. Test Time Augmentation para DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tta_predict_deberta(texts, model, tokenizer, n_augmentations=3):\n",
    "    all_predictions = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_inputs = tokenizer(texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "        outputs = model(**test_inputs)\n",
    "        all_predictions.append(torch.sigmoid(outputs.logits).cpu().numpy())\n",
    "    \n",
    "    for _ in range(n_augmentations):\n",
    "        model.train()\n",
    "        with torch.no_grad():\n",
    "            test_inputs = tokenizer(texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "            outputs = model(**test_inputs)\n",
    "            all_predictions.append(torch.sigmoid(outputs.logits).cpu().numpy())\n",
    "    \n",
    "    return np.mean(all_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28266286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset de test\n",
    "df_test = pd.read_csv(test_dir)\n",
    "df_test[\"text\"] = df_test[\"movie_name\"].fillna(\"\") + \" [SEP] \" + df_test[\"description\"].fillna(\"\")\n",
    "print(f\"Test dataset size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de222f13",
   "metadata": {},
   "source": [
    "## 12. Generaci√≥n de Predicciones Individuales en Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd61fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar features de test (SIN augmentation)\n",
    "print(\"Generating TF-IDF features for test...\")\n",
    "Xw_test = tfidf_word.transform(df_test[\"text\"])\n",
    "Xc_test = tfidf_char.transform(df_test[\"text\"])\n",
    "X_test_tfidf = sp_hstack([Xw_test, Xc_test], format=\"csr\")\n",
    "\n",
    "print(\"Generating BGE embeddings for test...\")\n",
    "emb_test = st_model.encode(df_test[\"text\"].tolist(), show_progress_bar=True, batch_size=16, normalize_embeddings=True)\n",
    "X_test_combined = sp_hstack([X_test_tfidf, csr_matrix(emb_test)], format=\"csr\")\n",
    "print(f\"Test features shape: {X_test_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LogisticRegression predictions\n",
    "print(\"Generating LogReg predictions...\")\n",
    "logits_logreg_test = clf_logreg.decision_function(X_test_combined)\n",
    "pred_logreg_test = (logits_logreg_test >= ths_logreg).astype(int)\n",
    "\n",
    "pred_labels_logreg = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_logreg_test]\n",
    "result_logreg = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_logreg,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_logreg.to_csv(\"dataset_test_preds_logreg.csv\", index=False)\n",
    "print(f\"‚úì LogReg predictions saved: dataset_test_preds_logreg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. XGBoost predictions\n",
    "print(\"Generating XGBoost predictions...\")\n",
    "pred_proba_xgb_test = clf_xgb.predict_proba(emb_test)\n",
    "logits_xgb_test = np.column_stack([p[:, 1] for p in pred_proba_xgb_test])\n",
    "pred_xgb_test = (logits_xgb_test >= ths_xgb).astype(int)\n",
    "\n",
    "pred_labels_xgb = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_xgb_test]\n",
    "result_xgb = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_xgb,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_xgb.to_csv(\"dataset_test_preds_xgb.csv\", index=False)\n",
    "print(f\"‚úì XGBoost predictions saved: dataset_test_preds_xgb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. LinearSVC predictions\n",
    "print(\"Generating LinearSVC predictions...\")\n",
    "logits_svc_test = clf_svc.decision_function(X_test_tfidf)\n",
    "pred_svc_test = (logits_svc_test >= ths_svc).astype(int)\n",
    "\n",
    "pred_labels_svc = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_svc_test]\n",
    "result_svc = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_svc,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_svc.to_csv(\"dataset_test_preds_svc.csv\", index=False)\n",
    "print(f\"‚úì LinearSVC predictions saved: dataset_test_preds_svc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calibrated SVC predictions\n",
    "print(\"Generating Calibrated SVC predictions...\")\n",
    "logits_svc_test_cal = np.column_stack([\n",
    "    clf_svc_calibrated.predict_proba(X_test_tfidf)[:, :, 1].T\n",
    "])\n",
    "pred_svc_cal_test = (logits_svc_test_cal >= ths_svc_cal).astype(int)\n",
    "\n",
    "pred_labels_svc_cal = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_svc_cal_test]\n",
    "result_svc_cal = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_svc_cal,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_svc_cal.to_csv(\"dataset_test_preds_svc_calibrated.csv\", index=False)\n",
    "print(f\"‚úì Calibrated SVC predictions saved: dataset_test_preds_svc_calibrated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. DistilBERT predictions\n",
    "print(\"Generating DistilBERT predictions...\")\n",
    "model_distilbert.eval()\n",
    "with torch.no_grad():\n",
    "    test_inputs = tokenizer_distilbert(df_test[\"text\"].tolist(), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "    outputs = model_distilbert(**test_inputs)\n",
    "    logits_distilbert_test = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "\n",
    "pred_distilbert_test = (logits_distilbert_test >= ths_distilbert).astype(int)\n",
    "\n",
    "pred_labels_distilbert = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_distilbert_test]\n",
    "result_distilbert = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_distilbert,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_distilbert.to_csv(\"dataset_test_preds_distilbert.csv\", index=False)\n",
    "print(f\"‚úì DistilBERT predictions saved: dataset_test_preds_distilbert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. DeBERTa predictions with TTA\n",
    "print(\"Generating DeBERTa predictions with TTA...\")\n",
    "logits_deberta_test_tta = tta_predict_deberta(df_test[\"text\"].tolist(), model_deberta, tokenizer_deberta)\n",
    "pred_deberta_test = (logits_deberta_test_tta >= ths_deberta).astype(int)\n",
    "\n",
    "pred_labels_deberta = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_deberta_test]\n",
    "result_deberta = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_deberta,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_deberta.to_csv(\"dataset_test_preds_deberta.csv\", index=False)\n",
    "print(f\"‚úì DeBERTa predictions saved: dataset_test_preds_deberta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a809b",
   "metadata": {},
   "source": [
    "## 13. Ensemble Final - Selecci√≥n del Mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53715ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear ensemble ponderado optimizado\n",
    "print(\"Creating optimized weighted ensemble...\")\n",
    "ensemble_optimized_test = (w_deberta_opt * logits_deberta_test_tta + \n",
    "                           w_distilbert_opt * logits_distilbert_test + \n",
    "                           w_logreg_opt * logits_logreg_test + \n",
    "                           w_xgb_opt * logits_xgb_test + \n",
    "                           w_svc_opt * logits_svc_test_cal)\n",
    "\n",
    "pred_optimized_test = (ensemble_optimized_test >= ths_optimized).astype(int)\n",
    "\n",
    "pred_labels_optimized = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_optimized_test]\n",
    "result_optimized = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_optimized,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_optimized.to_csv(\"dataset_test_preds_weighted_ensemble.csv\", index=False)\n",
    "print(f\"‚úì Weighted Ensemble predictions saved: dataset_test_preds_weighted_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear stacking ensemble\n",
    "print(\"Creating stacking ensemble...\")\n",
    "stacked_features_test = np.column_stack([\n",
    "    logits_deberta_test_tta,\n",
    "    logits_distilbert_test,\n",
    "    logits_logreg_test,\n",
    "    logits_xgb_test,\n",
    "    logits_svc_test_cal\n",
    "])\n",
    "\n",
    "pred_stacking_test = meta_model.predict(stacked_features_test)\n",
    "\n",
    "pred_labels_stacking = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_stacking_test]\n",
    "result_stacking = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_stacking,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_stacking.to_csv(\"dataset_test_preds_stacking_ensemble.csv\", index=False)\n",
    "print(f\"‚úì Stacking Ensemble predictions saved: dataset_test_preds_stacking_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar ensemble final para submission\n",
    "print(\"=\"*80)\n",
    "print(\"SELECTING BEST ENSEMBLE FOR FINAL SUBMISSION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Stacking Ensemble Validation F1: {metrics_stacking['f1']:.4f} (may be optimistic)\")\n",
    "print(f\"Weighted Ensemble Validation F1: {metrics_optimized['f1']:.4f} (more reliable)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# USAR SIEMPRE WEIGHTED ENSEMBLE (m√°s confiable, sin data leakage)\n",
    "print(f\"\\n‚úì USING WEIGHTED ENSEMBLE (F1={metrics_optimized['f1']:.4f}) for final submission\")\n",
    "print(\"  Reason: Optimized with Optuna on clean validation set, no data leakage\")\n",
    "final_submission = result_optimized.copy()\n",
    "final_submission.to_csv(\"dataset_test_preds.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úì‚úì‚úì FINAL SUBMISSION saved: dataset_test_preds.csv ‚úì‚úì‚úì\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e1a38",
   "metadata": {},
   "source": [
    "## 14. Resumen Final de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"VALIDATION PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"1. LogReg (TF-IDF+BGE):         F1: {metrics_logreg['f1']:.4f}, Hamming: {metrics_logreg['hamming_loss']:.4f}\")\n",
    "print(f\"2. XGBoost (BGE Embeddings):    F1: {metrics_xgb['f1']:.4f}, Hamming: {metrics_xgb['hamming_loss']:.4f}\")\n",
    "print(f\"3. LinearSVC (TF-IDF):          F1: {metrics_svc['f1']:.4f}, Hamming: {metrics_svc['hamming_loss']:.4f}\")\n",
    "print(f\"4. Calibrated SVC:              F1: {metrics_svc_cal['f1']:.4f}, Hamming: {metrics_svc_cal['hamming_loss']:.4f}\")\n",
    "print(f\"5. DistilBERT (Focal+Smooth):   F1: {metrics_distilbert['f1']:.4f}, Hamming: {metrics_distilbert['hamming_loss']:.4f}\")\n",
    "print(f\"6. DeBERTa-v3 (Focal+Smooth):   F1: {metrics_deberta['f1']:.4f}, Hamming: {metrics_deberta['hamming_loss']:.4f}\")\n",
    "print(f\"7. STACKING Ensemble:           F1: {metrics_stacking['f1']:.4f}, Hamming: {metrics_stacking['hamming_loss']:.4f} ‚ö†Ô∏è\")\n",
    "print(f\"8. WEIGHTED Ensemble (Optuna):  F1: {metrics_optimized['f1']:.4f}, Hamming: {metrics_optimized['hamming_loss']:.4f} ‚úì\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úì Data Augmentation: 35% of train only (validation untouched)\")\n",
    "print(f\"‚úì TF-IDF: n-grams (1,4) word + (3,6) char, max_features=750k\")\n",
    "print(f\"‚úì Embeddings: BGE-Large-en-v1.5 (1024 dim, normalized)\")\n",
    "print(f\"‚úì Loss: Focal Loss (alpha=0.25, gamma=2.0) + Label Smoothing (0.1)\")\n",
    "print(f\"‚úì Calibration: SVC with sigmoid on train (cv=3)\")\n",
    "print(f\"‚úì Ensemble: Weighted optimized with Optuna (F1 - 0.3*Hamming, 50 trials)\")\n",
    "print(f\"‚úì Metrics: All calculated with validator.py compute_metrics()\")\n",
    "print(f\"\\n‚ö†Ô∏è  Stacking trained on validation (may overfit) - Weighted Ensemble preferred\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARCHIVOS CSV GENERADOS PARA CADA MODELO:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. dataset_test_preds_logreg.csv\")\n",
    "print(\"2. dataset_test_preds_xgb.csv\")\n",
    "print(\"3. dataset_test_preds_svc.csv\")\n",
    "print(\"4. dataset_test_preds_svc_calibrated.csv\")\n",
    "print(\"5. dataset_test_preds_distilbert.csv\")\n",
    "print(\"6. dataset_test_preds_deberta.csv\")\n",
    "print(\"7. dataset_test_preds_weighted_ensemble.csv\")\n",
    "print(\"8. dataset_test_preds_stacking_ensemble.csv\")\n",
    "print(\"9. dataset_test_preds.csv (MEJOR ENSEMBLE - ENVIAR ESTE)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74138a24",
   "metadata": {},
   "source": [
    "## üìù C√ìMO SE GENERA EL ARCHIVO FINAL\n",
    "\n",
    "El archivo **`dataset_test_preds.csv`** se genera as√≠:\n",
    "\n",
    "1. **Se entrenan 6 modelos** en el dataset de train:\n",
    "   - LogisticRegression, XGBoost, LinearSVC, Calibrated SVC, DistilBERT, DeBERTa\n",
    "\n",
    "2. **Cada modelo genera predicciones en test** ‚Üí 6 archivos CSV individuales\n",
    "\n",
    "3. **Se crean 2 ensembles**:\n",
    "   - **Weighted Ensemble**: Combina los 6 modelos con pesos optimizados por Optuna\n",
    "   - **Stacking Ensemble**: Usa un meta-modelo Ridge para combinar predicciones\n",
    "\n",
    "4. **Se selecciona el mejor ensemble** basado en F1 score de validaci√≥n:\n",
    "   - Si `metrics_stacking['f1'] > metrics_optimized['f1']` ‚Üí usa Stacking\n",
    "   - Si no ‚Üí usa Weighted Ensemble (recomendado, m√°s confiable)\n",
    "\n",
    "5. **El mejor ensemble se guarda como `dataset_test_preds.csv`** ‚Üê **ESTE ES EL ARCHIVO FINAL PARA ENVIAR**\n",
    "\n",
    "**Resumen de archivos CSV generados:**\n",
    "- 6 archivos individuales por modelo (para an√°lisis)\n",
    "- 2 archivos de ensemble (weighted y stacking)\n",
    "- **1 archivo final: `dataset_test_preds.csv`** ‚úÖ ‚Üê Enviar este"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
