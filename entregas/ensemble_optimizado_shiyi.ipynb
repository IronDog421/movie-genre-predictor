{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f02983d",
   "metadata": {},
   "source": [
    "# Ensemble Optimizado para Predicción de Géneros\n",
    "\n",
    "Este notebook implementa un ensemble avanzado con:\n",
    "- Data augmentation (back-translation)\n",
    "- DeBERTa-v3 (modelo top del leaderboard)\n",
    "- Optimización de pesos con Optuna\n",
    "- Test-time augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770b8d4",
   "metadata": {},
   "source": [
    "## 1. Imports y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973ad285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.sparse import hstack as sp_hstack, csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, DistilBertForSequenceClassification,\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    Trainer, TrainingArguments,\n",
    "    MarianMTModel, MarianTokenizer\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar función de validación\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from validator import compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7131b8",
   "metadata": {},
   "source": [
    "## 2. Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb3a087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 8475\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "movie_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "genre",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "description",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "86d5fa1a-1add-4f1d-a39f-b6d539df8830",
       "rows": [
        [
         "0",
         "Silent Hill",
         "Horror, Mystery",
         "Rose, a desperate mother takes her adopted daughter, Sharon, to the town of Silent Hill in an attempt to cure her of her ailment. After a violent car crash, Sharon disappears and Rose begins a desperate search to get her back. She descends into the center of the twisted reality of a town's terrible secret. Pursued by grotesquely deformed creatures and townspeople stuck in permanent purgatory, Rose begins to uncover the truth behind the apocalyptic disaster that burned the town 30 years earlier."
        ],
        [
         "1",
         "Breaking the Waves",
         "Drama, Romance",
         "In a small and conservative Scottish village, a woman's paralytic husband convinces her to have extramarital intercourse so she can tell him about it and give him a reason for living."
        ],
        [
         "2",
         "Wind Chill",
         "Drama, Horror, Thriller",
         "Two college students share a ride home for the holidays. When they break down on a deserted stretch of road, they're preyed upon by the ghosts of people who have died there."
        ],
        [
         "3",
         "Godmothered",
         "Family, Fantasy, Comedy",
         "A young and unskilled fairy godmother that ventures out on her own to prove her worth by tracking down a young girl whose request for help was ignored. What she discovers is that the girl has now become a grown woman in need of something very different than a \"prince charming.\""
        ],
        [
         "4",
         "Donkey Skin",
         "Fantasy, Comedy, Music, Romance",
         "A fairy godmother helps a princess disguise herself so she won't have to marry her father."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silent Hill</td>\n",
       "      <td>Horror, Mystery</td>\n",
       "      <td>Rose, a desperate mother takes her adopted dau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breaking the Waves</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>In a small and conservative Scottish village, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wind Chill</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>Two college students share a ride home for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Godmothered</td>\n",
       "      <td>Family, Fantasy, Comedy</td>\n",
       "      <td>A young and unskilled fairy godmother that ven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donkey Skin</td>\n",
       "      <td>Fantasy, Comedy, Music, Romance</td>\n",
       "      <td>A fairy godmother helps a princess disguise he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_name                            genre  \\\n",
       "0         Silent Hill                  Horror, Mystery   \n",
       "1  Breaking the Waves                   Drama, Romance   \n",
       "2          Wind Chill          Drama, Horror, Thriller   \n",
       "3         Godmothered          Family, Fantasy, Comedy   \n",
       "4         Donkey Skin  Fantasy, Comedy, Music, Romance   \n",
       "\n",
       "                                         description  \n",
       "0  Rose, a desperate mother takes her adopted dau...  \n",
       "1  In a small and conservative Scottish village, ...  \n",
       "2  Two college students share a ride home for the...  \n",
       "3  A young and unskilled fairy godmother that ven...  \n",
       "4  A fairy godmother helps a princess disguise he...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = Path(\"../../dataset_train.csv\")\n",
    "test_dir = Path(\"../../dataset_test.csv\")\n",
    "\n",
    "df = pd.read_csv(train_dir)\n",
    "print(f\"Dataset size: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d9e662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 18\n",
      "Label distribution shape: (8475, 18)\n"
     ]
    }
   ],
   "source": [
    "df[\"text\"] = df[\"movie_name\"].fillna(\"\") + \" [SEP] \" + df[\"description\"].fillna(\"\")\n",
    "y_list = df[\"genre\"].apply(lambda s: [g.strip() for g in str(s).split(\",\") if g.strip()])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(y_list)\n",
    "\n",
    "print(f\"Number of labels: {len(mlb.classes_)}\")\n",
    "print(f\"Label distribution shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b339d",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation - Back Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223eb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translate(texts, src_lang='en', pivot_lang='fr', sample_ratio=0.2):\n",
    "    model_name_en_pivot = f'Helsinki-NLP/opus-mt-{src_lang}-{pivot_lang}'\n",
    "    model_name_pivot_en = f'Helsinki-NLP/opus-mt-{pivot_lang}-{src_lang}'\n",
    "    \n",
    "    tokenizer_en_pivot = MarianTokenizer.from_pretrained(model_name_en_pivot)\n",
    "    model_en_pivot = MarianMTModel.from_pretrained(model_name_en_pivot)\n",
    "    \n",
    "    tokenizer_pivot_en = MarianTokenizer.from_pretrained(model_name_pivot_en)\n",
    "    model_pivot_en = MarianMTModel.from_pretrained(model_name_pivot_en)\n",
    "    \n",
    "    augmented_texts = []\n",
    "    indices_to_augment = np.random.choice(len(texts), size=int(len(texts) * sample_ratio), replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices_to_augment):\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Augmenting {i}/{len(indices_to_augment)}...\", end='\\r')\n",
    "        \n",
    "        text = texts.iloc[idx] if hasattr(texts, 'iloc') else texts[idx]\n",
    "        \n",
    "        translated = model_en_pivot.generate(**tokenizer_en_pivot(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128))\n",
    "        pivot_text = tokenizer_en_pivot.decode(translated[0], skip_special_tokens=True)\n",
    "        \n",
    "        back_translated = model_pivot_en.generate(**tokenizer_pivot_en(pivot_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128))\n",
    "        final_text = tokenizer_pivot_en.decode(back_translated[0], skip_special_tokens=True)\n",
    "        \n",
    "        augmented_texts.append(final_text)\n",
    "    \n",
    "    print(f\"Augmentation complete!\" + \" \"*20)\n",
    "    return augmented_texts, indices_to_augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b7154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original - Training: 7627, Validation: 848\n",
      "\n",
      "Augmenting training data (parallelized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 274 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 301 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 417 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 448 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 481 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 514 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 549 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 584 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 621 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 697 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 777 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 818 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 861 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 904 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 949 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 994 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1041 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1088 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1137 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1237 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1288 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1341 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1394 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1449 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1504 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1561 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1618 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1677 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1736 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1797 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1858 tasks      | elapsed: 27.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1921 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1984 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2049 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2114 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2181 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2248 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2317 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2386 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2457 tasks      | elapsed: 36.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2528 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2601 tasks      | elapsed: 38.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented - Training: 10296, Validation: 848 (unchanged)\n",
      "Train augmentation: +2669 samples (35.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2669 out of 2669 | elapsed: 38.8min finished\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def back_translate_single(text, src_lang='en', pivot_lang='fr'):\n",
    "    \"\"\"Traduce un solo texto usando back-translation\"\"\"\n",
    "    model_name_en_pivot = f'Helsinki-NLP/opus-mt-{src_lang}-{pivot_lang}'\n",
    "    model_name_pivot_en = f'Helsinki-NLP/opus-mt-{pivot_lang}-{src_lang}'\n",
    "    \n",
    "    tokenizer_en_pivot = MarianTokenizer.from_pretrained(model_name_en_pivot)\n",
    "    model_en_pivot = MarianMTModel.from_pretrained(model_name_en_pivot)\n",
    "    \n",
    "    tokenizer_pivot_en = MarianTokenizer.from_pretrained(model_name_pivot_en)\n",
    "    model_pivot_en = MarianMTModel.from_pretrained(model_name_pivot_en)\n",
    "    \n",
    "    # EN -> FR\n",
    "    translated = model_en_pivot.generate(\n",
    "        **tokenizer_en_pivot(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    )\n",
    "    pivot_text = tokenizer_en_pivot.decode(translated[0], skip_special_tokens=True)\n",
    "    \n",
    "    # FR -> EN\n",
    "    back_translated = model_pivot_en.generate(\n",
    "        **tokenizer_pivot_en(pivot_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    )\n",
    "    final_text = tokenizer_pivot_en.decode(back_translated[0], skip_special_tokens=True)\n",
    "    \n",
    "    return final_text\n",
    "\n",
    "# Split ANTES de augmentar\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(df[\"text\"], Y, test_size=0.1, random_state=42)\n",
    "print(f\"Original - Training: {len(X_tr)}, Validation: {len(X_va)}\")\n",
    "\n",
    "# Seleccionar índices a augmentar\n",
    "print(f\"\\nAugmenting training data (parallelized)...\")\n",
    "aug_indices = np.random.choice(len(X_tr), size=int(len(X_tr) * 0.35), replace=False)\n",
    "texts_to_augment = [X_tr.iloc[idx] if hasattr(X_tr, 'iloc') else X_tr[idx] for idx in aug_indices]\n",
    "\n",
    "# Paralelizar back-translation con joblib (n_jobs=-1 usa todos los cores)\n",
    "augmented_texts = Parallel(n_jobs=-1, verbose=10, backend='loky')(\n",
    "    delayed(back_translate_single)(text) for text in texts_to_augment\n",
    ")\n",
    "\n",
    "# Obtener labels correspondientes\n",
    "y_tr_augmented = y_tr[aug_indices]\n",
    "\n",
    "# Combinar train original + augmentado\n",
    "X_tr_combined = pd.concat([X_tr.reset_index(drop=True), pd.Series(augmented_texts)], ignore_index=True)\n",
    "y_tr_combined = np.vstack([y_tr, y_tr_augmented])\n",
    "\n",
    "print(f\"Augmented - Training: {len(X_tr_combined)}, Validation: {len(X_va)} (unchanged)\")\n",
    "print(f\"Train augmentation: +{len(augmented_texts)} samples ({len(augmented_texts)/len(X_tr):.1%})\")\n",
    "\n",
    "# Actualizar variables\n",
    "X_tr = X_tr_combined\n",
    "y_tr = y_tr_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232fdd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f7925a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_va_nvembed.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_tr, \"X_tr_nvembed.pkl\")\n",
    "joblib.dump(X_va, \"X_va_nvembed.pkl\")\n",
    "joblib.dump(y_tr, \"y_tr_nvembed.pkl\")\n",
    "joblib.dump(y_va, \"y_va_nvembed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2434d4e",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b7b233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined TF-IDF features shape: (10296, 267716)\n"
     ]
    }
   ],
   "source": [
    "tfidf_word = TfidfVectorizer(\n",
    "    ngram_range=(1,4),\n",
    "    min_df=2,\n",
    "    max_features=750_000,\n",
    "    sublinear_tf=True,\n",
    "    stop_words=\"english\",\n",
    "    max_df=0.85,\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "tfidf_char = TfidfVectorizer(\n",
    "    analyzer=\"char_wb\",\n",
    "    ngram_range=(3,6),\n",
    "    min_df=2,\n",
    "    max_features=750_000,\n",
    "    sublinear_tf=True,\n",
    "    max_df=0.85,\n",
    "    strip_accents='unicode'\n",
    ")\n",
    "\n",
    "Xw_tr = tfidf_word.fit_transform(X_tr)\n",
    "Xw_va = tfidf_word.transform(X_va)\n",
    "Xc_tr = tfidf_char.fit_transform(X_tr)\n",
    "Xc_va = tfidf_char.transform(X_va)\n",
    "\n",
    "XTR_tfidf = sp_hstack([Xw_tr, Xc_tr], format=\"csr\")\n",
    "XVA_tfidf = sp_hstack([Xw_va, Xc_va], format=\"csr\")\n",
    "print(f\"Combined TF-IDF features shape: {XTR_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4edec731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorizers, MLB and labels.json saved!\n",
      "Number of labels: 18\n"
     ]
    }
   ],
   "source": [
    "# Guardar TF-IDF vectorizers, MultiLabelBinarizer y labels\n",
    "joblib.dump(tfidf_word, \"tfidf_word.joblib\")\n",
    "joblib.dump(tfidf_char, \"tfidf_char.joblib\")\n",
    "joblib.dump(mlb, \"mlb.joblib\")\n",
    "\n",
    "# Guardar labels.json\n",
    "import json\n",
    "labels_dict = {\"labels\": mlb.classes_.tolist()}\n",
    "with open(\"labels.json\", \"w\") as f:\n",
    "    json.dump(labels_dict, f, indent=2)\n",
    "\n",
    "print(\"TF-IDF vectorizers, MLB and labels.json saved!\")\n",
    "print(f\"Number of labels: {len(mlb.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3769ce1",
   "metadata": {},
   "source": [
    "## 5. Embeddings Mejorados (BGE-Large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b2148dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings with BGE-Large (1024 dim)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46fe4f2cb304cdbb812424fc7a32a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/644 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab23e4e6df746f9a23214f04aebed94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features (TF-IDF + BGE Embeddings) shape: (10296, 268740)\n"
     ]
    }
   ],
   "source": [
    "st_model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
    "print(\"Generating embeddings with BGE-Large (1024 dim)...\")\n",
    "emb_tr = st_model.encode(X_tr.tolist(), show_progress_bar=True, batch_size=16, normalize_embeddings=True)\n",
    "emb_va = st_model.encode(X_va.tolist(), show_progress_bar=True, batch_size=16, normalize_embeddings=True)\n",
    "\n",
    "XTR_combined = sp_hstack([XTR_tfidf, csr_matrix(emb_tr)], format=\"csr\")\n",
    "XVA_combined = sp_hstack([XVA_tfidf, csr_matrix(emb_va)], format=\"csr\")\n",
    "print(f\"Combined features (TF-IDF + BGE Embeddings) shape: {XTR_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1196daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Transformer model saved!\n"
     ]
    }
   ],
   "source": [
    "# Guardar sentence transformer model\n",
    "joblib.dump(st_model, \"sentence_transformer.joblib\")\n",
    "print(\"Sentence Transformer model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d796aa",
   "metadata": {},
   "source": [
    "## 6. Calibración y Modelos Mejorados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89b6db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression...\n",
      "LogReg training complete!\n"
     ]
    }
   ],
   "source": [
    "clf_logreg = OneVsRestClassifier(\n",
    "    LogisticRegression(C=8.0, solver=\"saga\", max_iter=4000, class_weight='balanced', random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(\"Training LogisticRegression...\")\n",
    "clf_logreg.fit(XTR_combined, y_tr)\n",
    "print(\"LogReg training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4045bc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg - F1: 0.6345, Precision: 0.6109, Recall: 0.6791, Hamming: 0.1021\n"
     ]
    }
   ],
   "source": [
    "logits_logreg = clf_logreg.decision_function(XVA_combined)\n",
    "ths_logreg = np.zeros(logits_logreg.shape[1])\n",
    "\n",
    "for k in range(logits_logreg.shape[1]):\n",
    "    s = logits_logreg[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_logreg[k] = best_t\n",
    "\n",
    "pred_logreg = (logits_logreg >= ths_logreg).astype(int)\n",
    "metrics_logreg = compute_metrics(y_va, pred_logreg)\n",
    "print(f\"LogReg - F1: {metrics_logreg['f1']:.4f}, Precision: {metrics_logreg['precision']:.4f}, Recall: {metrics_logreg['recall']:.4f}, Hamming: {metrics_logreg['hamming_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6612e6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.13561320754716982, 'f1': 0.6344655126996935, 'precision': 0.6109434298622106, 'recall': 0.6791274512706784, 'hamming_loss': 0.10213574423480083}\n"
     ]
    }
   ],
   "source": [
    "print(compute_metrics(y_va, pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de8473c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg model saved!\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo LogReg\n",
    "joblib.dump(clf_logreg, \"clf_logreg.joblib\")\n",
    "joblib.dump(ths_logreg, \"ths_logreg.npy\")\n",
    "print(\"LogReg model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a7c0a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "XGBoost training complete!\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = MultiOutputClassifier(\n",
    "    XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
    ")\n",
    "print(\"Training XGBoost...\")\n",
    "clf_xgb.fit(emb_tr, y_tr)\n",
    "print(\"XGBoost training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be8ba68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - F1: 0.6224, Precision: 0.5908, Recall: 0.6764, Hamming: 0.1046\n"
     ]
    }
   ],
   "source": [
    "pred_proba_xgb = clf_xgb.predict_proba(emb_va)\n",
    "logits_xgb = np.column_stack([p[:, 1] for p in pred_proba_xgb])\n",
    "ths_xgb = np.zeros(logits_xgb.shape[1])\n",
    "\n",
    "for k in range(logits_xgb.shape[1]):\n",
    "    s = logits_xgb[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_xgb[k] = best_t\n",
    "\n",
    "pred_xgb = (logits_xgb >= ths_xgb).astype(int)\n",
    "metrics_xgb = compute_metrics(y_va, pred_xgb)\n",
    "print(f\"XGBoost - F1: {metrics_xgb['f1']:.4f}, Precision: {metrics_xgb['precision']:.4f}, Recall: {metrics_xgb['recall']:.4f}, Hamming: {metrics_xgb['hamming_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa13fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model saved!\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo XGBoost\n",
    "joblib.dump(clf_xgb, \"clf_xgb.joblib\")\n",
    "joblib.dump(ths_xgb, \"ths_xgb.npy\")\n",
    "print(\"XGBoost model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f5c496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinearSVC...\n",
      "SVC training complete!\n"
     ]
    }
   ],
   "source": [
    "clf_svc = OneVsRestClassifier(\n",
    "    LinearSVC(C=2.0, max_iter=4000, class_weight='balanced', dual='auto', random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(\"Training LinearSVC...\")\n",
    "clf_svc.fit(XTR_tfidf, y_tr)\n",
    "print(\"SVC training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a554fc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC - F1: 0.5655, Precision: 0.5320, Recall: 0.6326, Hamming: 0.1238\n"
     ]
    }
   ],
   "source": [
    "logits_svc = clf_svc.decision_function(XVA_tfidf)\n",
    "ths_svc = np.zeros(logits_svc.shape[1])\n",
    "\n",
    "for k in range(logits_svc.shape[1]):\n",
    "    s = logits_svc[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_svc[k] = best_t\n",
    "\n",
    "pred_svc = (logits_svc >= ths_svc).astype(int)\n",
    "metrics_svc = compute_metrics(y_va, pred_svc)\n",
    "print(f\"LinearSVC - F1: {metrics_svc['f1']:.4f}, Precision: {metrics_svc['precision']:.4f}, Recall: {metrics_svc['recall']:.4f}, Hamming: {metrics_svc['hamming_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d4a0d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC model saved!\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo SVC\n",
    "joblib.dump(clf_svc, \"clf_svc.joblib\")\n",
    "joblib.dump(ths_svc, \"ths_svc.npy\")\n",
    "print(\"SVC model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc6674",
   "metadata": {},
   "source": [
    "## Calibración Probabilística SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbf27e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating SVC probabilities with cross-validation on TRAIN...\n",
      "Training base SVC models...\n",
      "Training label 16/18...\n",
      "Calibration complete for 18 labels!\n",
      "Generating calibrated probabilities on validation set...\n",
      "Calibrated SVC - F1: 0.5739, Precision: 0.5497, Recall: 0.6308, Hamming: 0.1203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "print(\"Calibrating SVC probabilities with cross-validation on TRAIN...\")\n",
    "# IMPORTANTE: Calibrar usando TRAIN, no validación (evitar data leakage)\n",
    "\n",
    "# Solución: Entrenar SVC sin OneVsRestClassifier primero, luego calibrar cada clasificador individualmente\n",
    "print(\"Training base SVC models...\")\n",
    "base_svc_models = []\n",
    "n_labels = y_tr.shape[1]\n",
    "\n",
    "for k in range(n_labels):\n",
    "    if k % 5 == 0:\n",
    "        print(f\"Training label {k+1}/{n_labels}...\", end='\\r')\n",
    "    \n",
    "    # Entrenar SVC para cada label\n",
    "    svc = LinearSVC(C=2.0, max_iter=4000, class_weight='balanced', dual='auto', random_state=42)\n",
    "    \n",
    "    # Calibrar con cross-validation en TRAIN\n",
    "    calibrated_svc = CalibratedClassifierCV(svc, cv=3, method='sigmoid')\n",
    "    calibrated_svc.fit(XTR_tfidf, y_tr[:, k])\n",
    "    \n",
    "    base_svc_models.append(calibrated_svc)\n",
    "\n",
    "print(f\"\\nCalibration complete for {n_labels} labels!\")\n",
    "\n",
    "# Obtener probabilidades calibradas en VALIDACIÓN\n",
    "print(\"Generating calibrated probabilities on validation set...\")\n",
    "logits_svc_cal = np.zeros((XVA_tfidf.shape[0], n_labels))\n",
    "\n",
    "for k, model in enumerate(base_svc_models):\n",
    "    logits_svc_cal[:, k] = model.predict_proba(XVA_tfidf)[:, 1]\n",
    "\n",
    "# Re-optimizar thresholds con calibración\n",
    "ths_svc_cal = np.zeros(logits_svc_cal.shape[1])\n",
    "for k in range(logits_svc_cal.shape[1]):\n",
    "    s = logits_svc_cal[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_svc_cal[k] = best_t\n",
    "\n",
    "pred_svc_cal = (logits_svc_cal >= ths_svc_cal).astype(int)\n",
    "metrics_svc_cal = compute_metrics(y_va, pred_svc_cal)\n",
    "print(f\"Calibrated SVC - F1: {metrics_svc_cal['f1']:.4f}, Precision: {metrics_svc_cal['precision']:.4f}, Recall: {metrics_svc_cal['recall']:.4f}, Hamming: {metrics_svc_cal['hamming_loss']:.4f}\")\n",
    "\n",
    "# Guardar modelos calibrados\n",
    "clf_svc_calibrated = base_svc_models  # Lista de modelos calibrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e1e99bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated SVC model saved!\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo SVC calibrado\n",
    "joblib.dump(clf_svc_calibrated, \"clf_svc_calibrated.joblib\")\n",
    "joblib.dump(ths_svc_cal, \"ths_svc_cal.npy\")\n",
    "print(\"Calibrated SVC model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccf671",
   "metadata": {},
   "source": [
    "## 7. DistilBERT con Focal Loss y Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a585825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal Loss class defined for DistilBERT\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss_fct = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "print(\"Focal Loss class defined for DistilBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cb91495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGenreDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx]) if hasattr(self.texts, 'iloc') else str(self.texts[idx])\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5a3def6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created: 10296 training, 848 validation\n"
     ]
    }
   ],
   "source": [
    "tokenizer_distilbert = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model_distilbert = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=len(mlb.classes_),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "train_dataset_distilbert = MovieGenreDataset(X_tr, y_tr, tokenizer_distilbert, max_length=128)\n",
    "val_dataset_distilbert = MovieGenreDataset(X_va, y_va, tokenizer_distilbert, max_length=128)\n",
    "print(f\"Datasets created: {len(train_dataset_distilbert)} training, {len(val_dataset_distilbert)} validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e94531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DistilBERT with Focal Loss + Label Smoothing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755d562fd76c4f9090ebb8b598c67554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0338, 'grad_norm': 0.051935646682977676, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0221, 'grad_norm': 0.07436374574899673, 'learning_rate': 2e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0185, 'grad_norm': 0.0721149668097496, 'learning_rate': 3e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0169, 'grad_norm': 0.07163507491350174, 'learning_rate': 4e-05, 'epoch': 0.62}\n",
      "{'loss': 0.016, 'grad_norm': 0.06319987773895264, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0154, 'grad_norm': 0.07618486881256104, 'learning_rate': 4.759152215799615e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8395c7acb6dd4a659d84be2222f276e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015020363964140415, 'eval_runtime': 1.5473, 'eval_samples_per_second': 548.05, 'eval_steps_per_second': 17.45, 'epoch': 1.0}\n",
      "{'loss': 0.0141, 'grad_norm': 0.08374618738889694, 'learning_rate': 4.518304431599229e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0131, 'grad_norm': 0.08397373557090759, 'learning_rate': 4.2774566473988445e-05, 'epoch': 1.24}\n",
      "{'loss': 0.0125, 'grad_norm': 0.0772162601351738, 'learning_rate': 4.036608863198459e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0121, 'grad_norm': 0.06960378587245941, 'learning_rate': 3.7957610789980736e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0119, 'grad_norm': 0.05488298088312149, 'learning_rate': 3.554913294797688e-05, 'epoch': 1.71}\n",
      "{'loss': 0.0116, 'grad_norm': 0.0836111307144165, 'learning_rate': 3.314065510597303e-05, 'epoch': 1.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256d266afeb64ee98de9623b65f00443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01436071377247572, 'eval_runtime': 1.5329, 'eval_samples_per_second': 553.194, 'eval_steps_per_second': 17.613, 'epoch': 2.0}\n",
      "{'loss': 0.0112, 'grad_norm': 0.06092393398284912, 'learning_rate': 3.073217726396917e-05, 'epoch': 2.02}\n",
      "{'loss': 0.0082, 'grad_norm': 0.0731116309762001, 'learning_rate': 2.832369942196532e-05, 'epoch': 2.17}\n",
      "{'loss': 0.0079, 'grad_norm': 0.08217909187078476, 'learning_rate': 2.5915221579961463e-05, 'epoch': 2.33}\n",
      "{'loss': 0.0081, 'grad_norm': 0.09230402857065201, 'learning_rate': 2.3506743737957612e-05, 'epoch': 2.48}\n",
      "{'loss': 0.0077, 'grad_norm': 0.06538791954517365, 'learning_rate': 2.1098265895953757e-05, 'epoch': 2.64}\n",
      "{'loss': 0.008, 'grad_norm': 0.07004916667938232, 'learning_rate': 1.8689788053949906e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0078, 'grad_norm': 0.08804482966661453, 'learning_rate': 1.628131021194605e-05, 'epoch': 2.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a707f4dee264421ac67a35d9a1319d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016173992305994034, 'eval_runtime': 1.5555, 'eval_samples_per_second': 545.146, 'eval_steps_per_second': 17.357, 'epoch': 3.0}\n",
      "{'loss': 0.0063, 'grad_norm': 0.05812007933855057, 'learning_rate': 1.3872832369942197e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0059, 'grad_norm': 0.06282991915941238, 'learning_rate': 1.1464354527938344e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0054, 'grad_norm': 0.04718885198235512, 'learning_rate': 9.05587668593449e-06, 'epoch': 3.42}\n",
      "{'loss': 0.0052, 'grad_norm': 0.03190620616078377, 'learning_rate': 6.647398843930635e-06, 'epoch': 3.57}\n",
      "{'loss': 0.0054, 'grad_norm': 0.04436526820063591, 'learning_rate': 4.238921001926782e-06, 'epoch': 3.73}\n",
      "{'loss': 0.0052, 'grad_norm': 0.06063408777117729, 'learning_rate': 1.8304431599229288e-06, 'epoch': 3.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c48b667390b445f8fdbdc5c1bed60d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017019927501678467, 'eval_runtime': 1.5582, 'eval_samples_per_second': 544.231, 'eval_steps_per_second': 17.328, 'epoch': 4.0}\n",
      "{'train_runtime': 195.5495, 'train_samples_per_second': 210.607, 'train_steps_per_second': 13.173, 'train_loss': 0.011425466328766775, 'epoch': 4.0}\n",
      "DistilBERT training complete!\n"
     ]
    }
   ],
   "source": [
    "training_args_distilbert = TrainingArguments(\n",
    "    output_dir='./distilbert_results',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    label_smoothing_factor=0.1,\n",
    ")\n",
    "\n",
    "trainer_distilbert = CustomTrainer(\n",
    "    model=model_distilbert,\n",
    "    args=training_args_distilbert,\n",
    "    train_dataset=train_dataset_distilbert,\n",
    "    eval_dataset=val_dataset_distilbert,\n",
    ")\n",
    "\n",
    "print(\"Training DistilBERT with Focal Loss + Label Smoothing...\")\n",
    "trainer_distilbert.train()\n",
    "print(\"DistilBERT training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "850d9aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processed 640/848 samples...\n",
      "Predictions complete! Shape: (848, 18)\n",
      "DistilBERT - F1: 0.6508, Precision: 0.6341, Recall: 0.6831, Hamming: 0.0927\n"
     ]
    }
   ],
   "source": [
    "# Configurar device (GPU si está disponible)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Mover modelo a GPU\n",
    "model_distilbert = model_distilbert.to(device)\n",
    "model_distilbert.eval()\n",
    "\n",
    "# Procesar por batches para evitar OOM (Out of Memory)\n",
    "batch_size = 32\n",
    "all_logits = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_va), batch_size):\n",
    "        batch_texts = X_va[i:i+batch_size].tolist()\n",
    "        \n",
    "        # Tokenizar y mover a GPU\n",
    "        val_inputs = tokenizer_distilbert(\n",
    "            batch_texts, \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            max_length=128, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        val_inputs = {k: v.to(device) for k, v in val_inputs.items()}\n",
    "        \n",
    "        # Forward pass en GPU\n",
    "        outputs = model_distilbert(**val_inputs)\n",
    "        \n",
    "        # Mover resultados a CPU y convertir a numpy\n",
    "        logits_batch = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "        all_logits.append(logits_batch)\n",
    "        \n",
    "        if (i // batch_size) % 10 == 0:\n",
    "            print(f\"Processed {i}/{len(X_va)} samples...\", end='\\r')\n",
    "\n",
    "# Concatenar todos los batches\n",
    "logits_distilbert = np.vstack(all_logits)\n",
    "print(f\"\\nPredictions complete! Shape: {logits_distilbert.shape}\")\n",
    "\n",
    "# Optimizar thresholds (esta parte se mantiene en CPU)\n",
    "ths_distilbert = np.zeros(logits_distilbert.shape[1])\n",
    "for k in range(logits_distilbert.shape[1]):\n",
    "    s = logits_distilbert[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_distilbert[k] = best_t\n",
    "\n",
    "pred_distilbert = (logits_distilbert >= ths_distilbert).astype(int)\n",
    "metrics_distilbert = compute_metrics(y_va, pred_distilbert)\n",
    "print(f\"DistilBERT - F1: {metrics_distilbert['f1']:.4f}, Precision: {metrics_distilbert['precision']:.4f}, Recall: {metrics_distilbert['recall']:.4f}, Hamming: {metrics_distilbert['hamming_loss']:.4f}\")\n",
    "\n",
    "# Liberar memoria GPU\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1703eab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT model saved!\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo DistilBERT\n",
    "model_distilbert.save_pretrained(\"./distilbert_model\")\n",
    "tokenizer_distilbert.save_pretrained(\"./distilbert_model\")\n",
    "np.save(\"ths_distilbert.npy\", ths_distilbert)\n",
    "print(\"DistilBERT model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e182905",
   "metadata": {},
   "source": [
    "## 8. DeBERTa-v3 (Top Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53240274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeBERTa datasets created\n"
     ]
    }
   ],
   "source": [
    "tokenizer_deberta = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "model_deberta = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-v3-base\",\n",
    "    num_labels=len(mlb.classes_),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "train_dataset_deberta = MovieGenreDataset(X_tr, y_tr, tokenizer_deberta, max_length=256)\n",
    "val_dataset_deberta = MovieGenreDataset(X_va, y_va, tokenizer_deberta, max_length=256)\n",
    "print(f\"DeBERTa datasets created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b37144ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DeBERTa-v3 with Focal Loss + Label Smoothing (8 epochs)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176fbb75f20d4369aacee53e67ecf8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0397, 'grad_norm': 0.1116500273346901, 'learning_rate': 3.883495145631068e-06, 'epoch': 0.16}\n",
      "{'loss': 0.0246, 'grad_norm': 0.07248342037200928, 'learning_rate': 7.766990291262136e-06, 'epoch': 0.31}\n",
      "{'loss': 0.0214, 'grad_norm': 0.09353857487440109, 'learning_rate': 1.1650485436893204e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0194, 'grad_norm': 0.09741342812776566, 'learning_rate': 1.5533980582524273e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0185, 'grad_norm': 0.08825855702161789, 'learning_rate': 1.9417475728155343e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0176, 'grad_norm': 0.10684588551521301, 'learning_rate': 1.9632750054007345e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d14c5e202d4e9bbc4beeee47b12ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01641504094004631, 'eval_runtime': 2.5902, 'eval_samples_per_second': 327.386, 'eval_steps_per_second': 20.462, 'epoch': 1.0}\n",
      "{'loss': 0.0164, 'grad_norm': 0.14727799594402313, 'learning_rate': 1.9200691294015988e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0161, 'grad_norm': 0.09319683164358139, 'learning_rate': 1.876863253402463e-05, 'epoch': 1.24}\n",
      "{'loss': 0.0156, 'grad_norm': 0.09917845577001572, 'learning_rate': 1.8336573774033272e-05, 'epoch': 1.4}\n",
      "{'loss': 0.015, 'grad_norm': 0.08475015312433243, 'learning_rate': 1.790451501404191e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0147, 'grad_norm': 0.08682149648666382, 'learning_rate': 1.747245625405055e-05, 'epoch': 1.71}\n",
      "{'loss': 0.0145, 'grad_norm': 0.08082383871078491, 'learning_rate': 1.7040397494059192e-05, 'epoch': 1.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bd8f4cb3aa41f1b65a9ccd0968c1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015101233497262001, 'eval_runtime': 2.6201, 'eval_samples_per_second': 323.653, 'eval_steps_per_second': 20.228, 'epoch': 2.0}\n",
      "{'loss': 0.0145, 'grad_norm': 0.09119341522455215, 'learning_rate': 1.6608338734067835e-05, 'epoch': 2.02}\n",
      "{'loss': 0.0128, 'grad_norm': 0.0995490625500679, 'learning_rate': 1.6176279974076477e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0124, 'grad_norm': 0.07082607597112656, 'learning_rate': 1.5744221214085116e-05, 'epoch': 2.33}\n",
      "{'loss': 0.0125, 'grad_norm': 0.10868402570486069, 'learning_rate': 1.5312162454093758e-05, 'epoch': 2.49}\n",
      "{'loss': 0.0122, 'grad_norm': 0.08975180983543396, 'learning_rate': 1.4880103694102399e-05, 'epoch': 2.64}\n",
      "{'loss': 0.0127, 'grad_norm': 0.11685547232627869, 'learning_rate': 1.4448044934111041e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0124, 'grad_norm': 0.10165052115917206, 'learning_rate': 1.4015986174119682e-05, 'epoch': 2.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4380be99664f423fb14ee9e7ba75758b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015021542087197304, 'eval_runtime': 2.599, 'eval_samples_per_second': 326.281, 'eval_steps_per_second': 20.393, 'epoch': 3.0}\n",
      "{'loss': 0.0113, 'grad_norm': 0.0949220284819603, 'learning_rate': 1.3583927414128322e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0107, 'grad_norm': 0.11432980000972748, 'learning_rate': 1.3151868654136963e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0106, 'grad_norm': 0.08933494985103607, 'learning_rate': 1.2719809894145605e-05, 'epoch': 3.42}\n",
      "{'loss': 0.0102, 'grad_norm': 0.09144226461648941, 'learning_rate': 1.2287751134154246e-05, 'epoch': 3.57}\n",
      "{'loss': 0.0106, 'grad_norm': 0.07471466809511185, 'learning_rate': 1.1855692374162888e-05, 'epoch': 3.73}\n",
      "{'loss': 0.0103, 'grad_norm': 0.10270533710718155, 'learning_rate': 1.1423633614171527e-05, 'epoch': 3.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce72c98ba60c4fa09e26cd686b9c85ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015729080885648727, 'eval_runtime': 2.6696, 'eval_samples_per_second': 317.647, 'eval_steps_per_second': 19.853, 'epoch': 4.0}\n",
      "{'loss': 0.0102, 'grad_norm': 0.06482283025979996, 'learning_rate': 1.099157485418017e-05, 'epoch': 4.04}\n",
      "{'loss': 0.0089, 'grad_norm': 0.10230880230665207, 'learning_rate': 1.055951609418881e-05, 'epoch': 4.2}\n",
      "{'loss': 0.0089, 'grad_norm': 0.07946794480085373, 'learning_rate': 1.0127457334197452e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0089, 'grad_norm': 0.09211118519306183, 'learning_rate': 9.695398574206093e-06, 'epoch': 4.51}\n",
      "{'loss': 0.009, 'grad_norm': 0.08780544996261597, 'learning_rate': 9.263339814214734e-06, 'epoch': 4.66}\n",
      "{'loss': 0.0091, 'grad_norm': 0.09670824557542801, 'learning_rate': 8.831281054223376e-06, 'epoch': 4.82}\n",
      "{'loss': 0.0087, 'grad_norm': 0.11529359966516495, 'learning_rate': 8.399222294232016e-06, 'epoch': 4.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0e644463e74732a2c4d112f7572d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016008129343390465, 'eval_runtime': 2.6157, 'eval_samples_per_second': 324.2, 'eval_steps_per_second': 20.263, 'epoch': 5.0}\n",
      "{'loss': 0.008, 'grad_norm': 0.08440888673067093, 'learning_rate': 7.967163534240657e-06, 'epoch': 5.13}\n",
      "{'loss': 0.0079, 'grad_norm': 0.08753979206085205, 'learning_rate': 7.5351047742492986e-06, 'epoch': 5.28}\n",
      "{'loss': 0.0076, 'grad_norm': 0.14622923731803894, 'learning_rate': 7.103046014257939e-06, 'epoch': 5.44}\n",
      "{'loss': 0.0072, 'grad_norm': 0.08542724698781967, 'learning_rate': 6.670987254266581e-06, 'epoch': 5.59}\n",
      "{'loss': 0.0074, 'grad_norm': 0.10288293659687042, 'learning_rate': 6.238928494275221e-06, 'epoch': 5.75}\n",
      "{'loss': 0.0075, 'grad_norm': 0.12135576456785202, 'learning_rate': 5.8068697342838636e-06, 'epoch': 5.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3777048b34cd409b9604056a200e70b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017079150304198265, 'eval_runtime': 2.644, 'eval_samples_per_second': 320.732, 'eval_steps_per_second': 20.046, 'epoch': 6.0}\n",
      "{'loss': 0.0072, 'grad_norm': 0.09334345161914825, 'learning_rate': 5.374810974292505e-06, 'epoch': 6.06}\n",
      "{'loss': 0.0067, 'grad_norm': 0.1035103127360344, 'learning_rate': 4.942752214301146e-06, 'epoch': 6.22}\n",
      "{'loss': 0.0066, 'grad_norm': 0.11541051417589188, 'learning_rate': 4.510693454309786e-06, 'epoch': 6.37}\n",
      "{'loss': 0.0065, 'grad_norm': 0.15289857983589172, 'learning_rate': 4.078634694318428e-06, 'epoch': 6.53}\n",
      "{'loss': 0.0063, 'grad_norm': 0.10909826308488846, 'learning_rate': 3.646575934327069e-06, 'epoch': 6.68}\n",
      "{'loss': 0.0065, 'grad_norm': 0.08515895903110504, 'learning_rate': 3.2145171743357102e-06, 'epoch': 6.84}\n",
      "{'loss': 0.0065, 'grad_norm': 0.09251238405704498, 'learning_rate': 2.7824584143443513e-06, 'epoch': 6.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb561cb0ad0b4a82a1f49417e149f9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017723752185702324, 'eval_runtime': 2.6116, 'eval_samples_per_second': 324.705, 'eval_steps_per_second': 20.294, 'epoch': 7.0}\n",
      "{'loss': 0.0063, 'grad_norm': 0.07889391481876373, 'learning_rate': 2.3503996543529923e-06, 'epoch': 7.15}\n",
      "{'loss': 0.0055, 'grad_norm': 0.0853276252746582, 'learning_rate': 1.9183408943616333e-06, 'epoch': 7.3}\n",
      "{'loss': 0.0058, 'grad_norm': 0.10247398912906647, 'learning_rate': 1.4862821343702744e-06, 'epoch': 7.46}\n",
      "{'loss': 0.0059, 'grad_norm': 0.11821724474430084, 'learning_rate': 1.0542233743789156e-06, 'epoch': 7.61}\n",
      "{'loss': 0.0059, 'grad_norm': 0.10575602203607559, 'learning_rate': 6.221646143875568e-07, 'epoch': 7.77}\n",
      "{'loss': 0.006, 'grad_norm': 0.09205249696969986, 'learning_rate': 1.901058543961979e-07, 'epoch': 7.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56259553e7a348f2b03da524f1d2993f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018022729083895683, 'eval_runtime': 2.6007, 'eval_samples_per_second': 326.06, 'eval_steps_per_second': 20.379, 'epoch': 7.99}\n",
      "{'train_runtime': 1083.3609, 'train_samples_per_second': 76.03, 'train_steps_per_second': 4.748, 'train_loss': 0.011278900750919968, 'epoch': 7.99}\n",
      "DeBERTa training complete!\n"
     ]
    }
   ],
   "source": [
    "training_args_deberta = TrainingArguments(\n",
    "    output_dir='./deberta_results',\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    "    label_smoothing_factor=0.1,\n",
    ")\n",
    "\n",
    "trainer_deberta = CustomTrainer(\n",
    "    model=model_deberta,\n",
    "    args=training_args_deberta,\n",
    "    train_dataset=train_dataset_deberta,\n",
    "    eval_dataset=val_dataset_deberta,\n",
    ")\n",
    "\n",
    "print(\"Training DeBERTa-v3 with Focal Loss + Label Smoothing (8 epochs)...\")\n",
    "trainer_deberta.train()\n",
    "print(\"DeBERTa training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86fa464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processed 800/848 samples...\n",
      "Predictions complete! Shape: (848, 18)\n",
      "DeBERTa-v3 - F1: 0.6385, Precision: 0.6263, Recall: 0.6805, Hamming: 0.0993\n"
     ]
    }
   ],
   "source": [
    "# Configurar device (GPU si está disponible)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Mover modelo a GPU\n",
    "model_deberta = model_deberta.to(device)\n",
    "model_deberta.eval()\n",
    "\n",
    "# Procesar por batches para evitar OOM (DeBERTa usa max_length=256, más memoria)\n",
    "batch_size = 16  # Más pequeño que DistilBERT debido a mayor tamaño de modelo\n",
    "all_logits = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_va), batch_size):\n",
    "        batch_texts = X_va[i:i+batch_size].tolist()\n",
    "        \n",
    "        # Tokenizar y mover a GPU\n",
    "        val_inputs = tokenizer_deberta(\n",
    "            batch_texts, \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            max_length=256, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        val_inputs = {k: v.to(device) for k, v in val_inputs.items()}\n",
    "        \n",
    "        # Forward pass en GPU\n",
    "        outputs = model_deberta(**val_inputs)\n",
    "        \n",
    "        # Mover resultados a CPU y convertir a numpy\n",
    "        logits_batch = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "        all_logits.append(logits_batch)\n",
    "        \n",
    "        if (i // batch_size) % 10 == 0:\n",
    "            print(f\"Processed {i}/{len(X_va)} samples...\", end='\\r')\n",
    "\n",
    "# Concatenar todos los batches\n",
    "logits_deberta = np.vstack(all_logits)\n",
    "print(f\"\\nPredictions complete! Shape: {logits_deberta.shape}\")\n",
    "\n",
    "# Optimizar thresholds (esta parte se mantiene en CPU)\n",
    "ths_deberta = np.zeros(logits_deberta.shape[1])\n",
    "for k in range(logits_deberta.shape[1]):\n",
    "    s = logits_deberta[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_deberta[k] = best_t\n",
    "\n",
    "pred_deberta = (logits_deberta >= ths_deberta).astype(int)\n",
    "metrics_deberta = compute_metrics(y_va, pred_deberta)\n",
    "print(f\"DeBERTa-v3 - F1: {metrics_deberta['f1']:.4f}, Precision: {metrics_deberta['precision']:.4f}, Recall: {metrics_deberta['recall']:.4f}, Hamming: {metrics_deberta['hamming_loss']:.4f}\")\n",
    "\n",
    "# Liberar memoria GPU\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87b14835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeBERTa model saved!\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo DeBERTa\n",
    "model_deberta.save_pretrained(\"./deberta_model\")\n",
    "tokenizer_deberta.save_pretrained(\"./deberta_model\")\n",
    "np.save(\"ths_deberta.npy\", ths_deberta)\n",
    "print(\"DeBERTa model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ef5aa",
   "metadata": {},
   "source": [
    "## 9. Ensemble con Stacking (Meta-learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0132966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked features shape: (848, 90)\n",
      "Training stacking meta-model...\n",
      "⚠️  WARNING: Training on validation set (not ideal but validation is small)\n",
      "Stacking Ensemble - F1: 0.6637, Precision: 0.7883, Recall: 0.5855, Hamming: 0.0710\n",
      "⚠️  These metrics may be optimistic - prefer Weighted Ensemble metrics for true performance\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "# NOTA IMPORTANTE: Stacking ideal requiere predicciones out-of-fold de TODOS los modelos\n",
    "# Los transformers (DistilBERT/DeBERTa) no tienen OOF fácilmente disponible\n",
    "# Por simplicidad y evitar data leakage, usamos ensemble ponderado optimizado como principal\n",
    "# Guardamos el código de stacking pero es OPCIONAL y puede tener ligero overfitting\n",
    "\n",
    "# Stack todos los logits de VALIDACIÓN\n",
    "stacked_features_val = np.column_stack([\n",
    "    logits_deberta, \n",
    "    logits_distilbert, \n",
    "    logits_logreg, \n",
    "    logits_xgb, \n",
    "    logits_svc_cal\n",
    "])\n",
    "\n",
    "print(f\"Stacked features shape: {stacked_features_val.shape}\")\n",
    "\n",
    "# Meta-learner con Ridge Regression (regularizado para reducir overfitting)\n",
    "meta_model = OneVsRestClassifier(\n",
    "    RidgeClassifierCV(alphas=[0.1, 0.5, 1.0, 5.0, 10.0], cv=3),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training stacking meta-model...\")\n",
    "print(\"⚠️  WARNING: Training on validation set (not ideal but validation is small)\")\n",
    "meta_model.fit(stacked_features_val, y_va)\n",
    "\n",
    "# Predicciones del meta-model\n",
    "pred_stacking = meta_model.predict(stacked_features_val)\n",
    "metrics_stacking = compute_metrics(y_va, pred_stacking)\n",
    "print(f\"Stacking Ensemble - F1: {metrics_stacking['f1']:.4f}, Precision: {metrics_stacking['precision']:.4f}, Recall: {metrics_stacking['recall']:.4f}, Hamming: {metrics_stacking['hamming_loss']:.4f}\")\n",
    "print(f\"⚠️  These metrics may be optimistic - prefer Weighted Ensemble metrics for true performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b6cf3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking meta-model saved (use with caution - may be overfit)\n"
     ]
    }
   ],
   "source": [
    "# Guardar meta-model (opcional, prefer weighted ensemble)\n",
    "joblib.dump(meta_model, \"meta_model_stacking.joblib\")\n",
    "print(\"Stacking meta-model saved (use with caution - may be overfit)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d0441b",
   "metadata": {},
   "source": [
    "## 10. Optimización de Pesos con Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e523e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "def objective_with_hamming(trial):\n",
    "    w_deberta = trial.suggest_float(\"w_deberta\", 0.3, 0.6)\n",
    "    w_distilbert = trial.suggest_float(\"w_distilbert\", 0.1, 0.4)\n",
    "    w_logreg = trial.suggest_float(\"w_logreg\", 0.1, 0.3)\n",
    "    w_xgb = trial.suggest_float(\"w_xgb\", 0.05, 0.25)\n",
    "    w_svc = max(0.0, 1.0 - w_deberta - w_distilbert - w_logreg - w_xgb)\n",
    "    \n",
    "    ensemble_logits_opt = (w_deberta * logits_deberta + \n",
    "                           w_distilbert * logits_distilbert + \n",
    "                           w_logreg * logits_logreg + \n",
    "                           w_xgb * logits_xgb + \n",
    "                           w_svc * logits_svc_cal)\n",
    "    \n",
    "    # Optimizar thresholds\n",
    "    ths_opt = np.zeros(ensemble_logits_opt.shape[1])\n",
    "    for k in range(ensemble_logits_opt.shape[1]):\n",
    "        s = ensemble_logits_opt[:, k]\n",
    "        best_f1, best_t = 0.0, 0.0\n",
    "        candidates = np.quantile(s, np.linspace(0.01, 0.99, 50))\n",
    "        for t in candidates:\n",
    "            preds_k = (s >= t).astype(int)\n",
    "            f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "        ths_opt[k] = best_t\n",
    "    \n",
    "    pred_opt = (ensemble_logits_opt >= ths_opt).astype(int)\n",
    "    \n",
    "    # Combinar F1 macro y Hamming Loss\n",
    "    f1_macro = f1_score(y_va, pred_opt, average='macro')\n",
    "    hamming = hamming_loss(y_va, pred_opt)\n",
    "    \n",
    "    return f1_macro - 0.3 * hamming\n",
    "\n",
    "print(\"Optimizing ensemble weights (F1 macro - Hamming Loss)...\")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_with_hamming, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest score (F1 - 0.3*Hamming): {study.best_value:.4f}\")\n",
    "print(\"Best weights:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6da5fd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Ensemble - F1: 0.6519, Precision: 0.6733, Recall: 0.6602, Hamming: 0.0903\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w_deberta_opt = 0.4\n",
    "w_distilbert_opt = 0.4\n",
    "w_logreg_opt = 0.1\n",
    "w_xgb_opt = 0.1\n",
    "w_svc_opt = 1.0 - w_deberta_opt - w_distilbert_opt - w_logreg_opt - w_xgb_opt\n",
    "\n",
    "ensemble_optimized = (w_deberta_opt * logits_deberta + \n",
    "                      w_distilbert_opt * logits_distilbert + \n",
    "                      w_logreg_opt * logits_logreg + \n",
    "                      w_xgb_opt * logits_xgb + \n",
    "                      w_svc_opt * logits_svc_cal)\n",
    "\n",
    "# Optimización de thresholds con búsqueda más precisa\n",
    "ths_optimized = np.zeros(ensemble_optimized.shape[1])\n",
    "for k in range(ensemble_optimized.shape[1]):\n",
    "    s = ensemble_optimized[:, k]\n",
    "    best_f1, best_t = 0.0, 0.0\n",
    "    candidates = np.unique(np.quantile(s, np.linspace(0, 1, 100)))\n",
    "    for t in candidates:\n",
    "        preds_k = (s >= t).astype(int)\n",
    "        f1 = f1_score(y_va[:, k], preds_k, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    ths_optimized[k] = best_t\n",
    "\n",
    "# Ajuste para reducir Hamming Loss\n",
    "avg_labels_train = y_va.sum(axis=1).mean()\n",
    "for iteration in range(10):\n",
    "    pred_optimized = (ensemble_optimized >= ths_optimized).astype(int)\n",
    "    current_avg = pred_optimized.sum(axis=1).mean()\n",
    "    \n",
    "    if abs(current_avg - avg_labels_train) < 0.1:\n",
    "        break\n",
    "    \n",
    "    if current_avg > avg_labels_train:\n",
    "        ths_optimized *= 1.02\n",
    "    else:\n",
    "        ths_optimized *= 0.98\n",
    "\n",
    "pred_optimized = (ensemble_optimized >= ths_optimized).astype(int)\n",
    "metrics_optimized = compute_metrics(y_va, pred_optimized)\n",
    "print(f\"Optimized Ensemble - F1: {metrics_optimized['f1']:.4f}, Precision: {metrics_optimized['precision']:.4f}, Recall: {metrics_optimized['recall']:.4f}, Hamming: {metrics_optimized['hamming_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c5181",
   "metadata": {},
   "source": [
    "## 11. Test Time Augmentation para DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fdc72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tta_predict_deberta(texts, model, tokenizer, n_augmentations=3):\n",
    "    all_predictions = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_inputs = tokenizer(texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "        outputs = model(**test_inputs)\n",
    "        all_predictions.append(torch.sigmoid(outputs.logits).cpu().numpy())\n",
    "    \n",
    "    for _ in range(n_augmentations):\n",
    "        model.train()\n",
    "        with torch.no_grad():\n",
    "            test_inputs = tokenizer(texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "            outputs = model(**test_inputs)\n",
    "            all_predictions.append(torch.sigmoid(outputs.logits).cpu().numpy())\n",
    "    \n",
    "    return np.mean(all_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28266286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 942\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset de test\n",
    "df_test = pd.read_csv(test_dir)\n",
    "df_test[\"text\"] = df_test[\"movie_name\"].fillna(\"\") + \" [SEP] \" + df_test[\"description\"].fillna(\"\")\n",
    "print(f\"Test dataset size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de222f13",
   "metadata": {},
   "source": [
    "## 12. Generación de Predicciones Individuales en Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cecd61fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TF-IDF features for test...\n",
      "Generating BGE embeddings for test...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e0087ae6524ca3862df9b5a0e48735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features shape: (942, 268740)\n"
     ]
    }
   ],
   "source": [
    "# Generar features de test (SIN augmentation)\n",
    "print(\"Generating TF-IDF features for test...\")\n",
    "Xw_test = tfidf_word.transform(df_test[\"text\"])\n",
    "Xc_test = tfidf_char.transform(df_test[\"text\"])\n",
    "X_test_tfidf = sp_hstack([Xw_test, Xc_test], format=\"csr\")\n",
    "\n",
    "print(\"Generating BGE embeddings for test...\")\n",
    "emb_test = st_model.encode(df_test[\"text\"].tolist(), show_progress_bar=True, batch_size=16, normalize_embeddings=True)\n",
    "X_test_combined = sp_hstack([X_test_tfidf, csr_matrix(emb_test)], format=\"csr\")\n",
    "print(f\"Test features shape: {X_test_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dd3b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LogReg predictions...\n",
      "✓ LogReg predictions saved: dataset_test_preds_logreg.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. LogisticRegression predictions\n",
    "print(\"Generating LogReg predictions...\")\n",
    "logits_logreg_test = clf_logreg.decision_function(X_test_combined)\n",
    "pred_logreg_test = (logits_logreg_test >= ths_logreg).astype(int)\n",
    "\n",
    "pred_labels_logreg = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_logreg_test]\n",
    "result_logreg = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_logreg,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_logreg.to_csv(\"dataset_test_preds_logreg.csv\", index=False)\n",
    "print(f\"✓ LogReg predictions saved: dataset_test_preds_logreg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc80377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating XGBoost predictions...\n",
      "✓ XGBoost predictions saved: dataset_test_preds_xgb.csv\n"
     ]
    }
   ],
   "source": [
    "# 2. XGBoost predictions\n",
    "print(\"Generating XGBoost predictions...\")\n",
    "pred_proba_xgb_test = clf_xgb.predict_proba(emb_test)\n",
    "logits_xgb_test = np.column_stack([p[:, 1] for p in pred_proba_xgb_test])\n",
    "pred_xgb_test = (logits_xgb_test >= ths_xgb).astype(int)\n",
    "\n",
    "pred_labels_xgb = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_xgb_test]\n",
    "result_xgb = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_xgb,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_xgb.to_csv(\"dataset_test_preds_xgb.csv\", index=False)\n",
    "print(f\"✓ XGBoost predictions saved: dataset_test_preds_xgb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0afd3e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LinearSVC predictions...\n",
      "✓ LinearSVC predictions saved: dataset_test_preds_svc.csv\n"
     ]
    }
   ],
   "source": [
    "# 3. LinearSVC predictions\n",
    "print(\"Generating LinearSVC predictions...\")\n",
    "logits_svc_test = clf_svc.decision_function(X_test_tfidf)\n",
    "pred_svc_test = (logits_svc_test >= ths_svc).astype(int)\n",
    "\n",
    "pred_labels_svc = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_svc_test]\n",
    "result_svc = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_svc,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_svc.to_csv(\"dataset_test_preds_svc.csv\", index=False)\n",
    "print(f\"✓ LinearSVC predictions saved: dataset_test_preds_svc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3bd1a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Calibrated SVC predictions...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 4. Calibrated SVC predictions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating Calibrated SVC predictions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m logits_svc_test_cal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack([\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mclf_svc_calibrated\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(X_test_tfidf)[:, :, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      6\u001b[0m pred_svc_cal_test \u001b[38;5;241m=\u001b[39m (logits_svc_test_cal \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m ths_svc_cal)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      8\u001b[0m pred_labels_svc_cal \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([mlb\u001b[38;5;241m.\u001b[39mclasses_[j] \u001b[38;5;28;01mfor\u001b[39;00m j, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row) \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m pred_svc_cal_test]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "# 4. Calibrated SVC predictions\n",
    "print(\"Generating Calibrated SVC predictions...\")\n",
    "logits_svc_test_cal = np.column_stack([\n",
    "    clf_svc_calibrated.predict_proba(X_test_tfidf)[:, :, 1].T\n",
    "])\n",
    "pred_svc_cal_test = (logits_svc_test_cal >= ths_svc_cal).astype(int)\n",
    "\n",
    "pred_labels_svc_cal = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_svc_cal_test]\n",
    "result_svc_cal = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_svc_cal,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_svc_cal.to_csv(\"dataset_test_preds_svc_calibrated.csv\", index=False)\n",
    "print(f\"✓ Calibrated SVC predictions saved: dataset_test_preds_svc_calibrated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "447b76e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating DistilBERT predictions on TEST set...\n",
      "Using device: cuda\n",
      "Processed 640/942 test samples...\n",
      "Test predictions complete! Shape: (942, 18)\n",
      "✓ DistilBERT predictions saved: dataset_test_preds_distilbert.csv\n"
     ]
    }
   ],
   "source": [
    "# 5. DistilBERT predictions\n",
    "print(\"Generating DistilBERT predictions on TEST set...\")\n",
    "\n",
    "# Configurar device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Mover modelo a GPU\n",
    "model_distilbert = model_distilbert.to(device)\n",
    "model_distilbert.eval()\n",
    "\n",
    "# Procesar por batches\n",
    "batch_size = 32\n",
    "all_logits = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(df_test), batch_size):\n",
    "        batch_texts = df_test[\"text\"].iloc[i:i+batch_size].tolist()\n",
    "        \n",
    "        # Tokenizar y mover a GPU\n",
    "        test_inputs = tokenizer_distilbert(\n",
    "            batch_texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        test_inputs = {k: v.to(device) for k, v in test_inputs.items()}\n",
    "        \n",
    "        # Forward pass en GPU\n",
    "        outputs = model_distilbert(**test_inputs)\n",
    "        \n",
    "        # Mover resultados a CPU\n",
    "        logits_batch = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "        all_logits.append(logits_batch)\n",
    "        \n",
    "        if (i // batch_size) % 20 == 0:\n",
    "            print(f\"Processed {i}/{len(df_test)} test samples...\", end='\\r')\n",
    "\n",
    "# Concatenar todos los batches\n",
    "logits_distilbert_test = np.vstack(all_logits)\n",
    "print(f\"\\nTest predictions complete! Shape: {logits_distilbert_test.shape}\")\n",
    "\n",
    "# Aplicar thresholds optimizados\n",
    "pred_distilbert_test = (logits_distilbert_test >= ths_distilbert).astype(int)\n",
    "\n",
    "# Generar labels\n",
    "pred_labels_distilbert = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_distilbert_test]\n",
    "result_distilbert = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_distilbert,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_distilbert.to_csv(\"dataset_test_preds_distilbert.csv\", index=False)\n",
    "print(f\"✓ DistilBERT predictions saved: dataset_test_preds_distilbert.csv\")\n",
    "\n",
    "# Liberar memoria GPU\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb68af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating DeBERTa predictions with TTA on TEST set...\n",
      "Test dataset size: 942\n",
      "TTA base prediction: 800/942 samples...\n",
      "TTA base prediction complete!\n",
      "TTA augmentation 1/3: 800/942 samples...\n",
      "TTA augmentation 1/3 complete!\n",
      "TTA augmentation 2/3: 800/942 samples...\n",
      "TTA augmentation 2/3 complete!\n",
      "TTA augmentation 3/3: 800/942 samples...\n",
      "TTA augmentation 3/3 complete!\n",
      "TTA predictions complete! Shape: (942, 18)\n",
      "✓ DeBERTa predictions saved: dataset_test_preds_deberta.csv\n"
     ]
    }
   ],
   "source": [
    "def tta_predict_deberta(texts, model, tokenizer, n_augmentations=3, batch_size=16):\n",
    "    \"\"\"\n",
    "    Test-Time Augmentation para DeBERTa con GPU y batch processing\n",
    "    \n",
    "    Args:\n",
    "        texts: Lista de textos a predecir\n",
    "        model: Modelo DeBERTa\n",
    "        tokenizer: Tokenizer de DeBERTa\n",
    "        n_augmentations: Número de augmentaciones (dropout variations)\n",
    "        batch_size: Tamaño de batch (16 por defecto para DeBERTa)\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    # Primera predicción: modo eval (sin dropout)\n",
    "    model.eval()\n",
    "    batch_preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(\n",
    "                batch_texts, \n",
    "                truncation=True, \n",
    "                padding=True, \n",
    "                max_length=256, \n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            logits = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "            batch_preds.append(logits)\n",
    "            \n",
    "            if (i // batch_size) % 10 == 0:\n",
    "                print(f\"TTA base prediction: {i}/{len(texts)} samples...\", end='\\r')\n",
    "    \n",
    "    all_predictions.append(np.vstack(batch_preds))\n",
    "    print(f\"\\nTTA base prediction complete!\")\n",
    "    \n",
    "    # Augmentaciones adicionales: modo train (con dropout activado)\n",
    "    for aug_idx in range(n_augmentations):\n",
    "        model.train()  # Activa dropout para variabilidad\n",
    "        batch_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                inputs = tokenizer(\n",
    "                    batch_texts, \n",
    "                    truncation=True, \n",
    "                    padding=True, \n",
    "                    max_length=256, \n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                outputs = model(**inputs)\n",
    "                logits = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "                batch_preds.append(logits)\n",
    "                \n",
    "                if (i // batch_size) % 10 == 0:\n",
    "                    print(f\"TTA augmentation {aug_idx+1}/{n_augmentations}: {i}/{len(texts)} samples...\", end='\\r')\n",
    "        \n",
    "        all_predictions.append(np.vstack(batch_preds))\n",
    "        print(f\"\\nTTA augmentation {aug_idx+1}/{n_augmentations} complete!\")\n",
    "    \n",
    "    # Promediar todas las predicciones\n",
    "    final_predictions = np.mean(all_predictions, axis=0)\n",
    "    \n",
    "    # Liberar memoria GPU\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "# 6. DeBERTa predictions with TTA\n",
    "print(\"Generating DeBERTa predictions with TTA on TEST set...\")\n",
    "print(f\"Test dataset size: {len(df_test)}\")\n",
    "\n",
    "# Usar TTA optimizada\n",
    "logits_deberta_test_tta = tta_predict_deberta(\n",
    "    df_test[\"text\"].tolist(), \n",
    "    model_deberta, \n",
    "    tokenizer_deberta,\n",
    "    n_augmentations=3,\n",
    "    batch_size=16  # Ajusta según tu GPU (8 para <6GB, 24 para >12GB)\n",
    ")\n",
    "\n",
    "print(f\"TTA predictions complete! Shape: {logits_deberta_test_tta.shape}\")\n",
    "\n",
    "# Aplicar thresholds optimizados\n",
    "pred_deberta_test = (logits_deberta_test_tta >= ths_deberta).astype(int)\n",
    "\n",
    "# Generar labels\n",
    "pred_labels_deberta = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_deberta_test]\n",
    "result_deberta = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_deberta,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_deberta.to_csv(\"dataset_test_preds_deberta.csv\", index=False)\n",
    "print(f\"✓ DeBERTa predictions saved: dataset_test_preds_deberta.csv\")\n",
    "\n",
    "# Liberar memoria GPU final\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a809b",
   "metadata": {},
   "source": [
    "## 13. Ensemble Final - Selección del Mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53715ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating optimized weighted ensemble...\n",
      "✓ Weighted Ensemble predictions saved: dataset_test_preds_weighted_ensemble.csv\n"
     ]
    }
   ],
   "source": [
    "# Crear ensemble ponderado optimizado\n",
    "print(\"Creating optimized weighted ensemble...\")\n",
    "ensemble_optimized_test = (w_deberta_opt * logits_deberta_test_tta + \n",
    "                           w_distilbert_opt * logits_distilbert_test + \n",
    "                           w_logreg_opt * logits_logreg_test + \n",
    "                           w_xgb_opt * logits_xgb_test)\n",
    "\n",
    "pred_optimized_test = (ensemble_optimized_test >= ths_optimized).astype(int)\n",
    "\n",
    "pred_labels_optimized = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_optimized_test]\n",
    "result_optimized = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_optimized,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_optimized.to_csv(\"dataset_test_preds_weighted_ensemble.csv\", index=False)\n",
    "print(f\"✓ Weighted Ensemble predictions saved: dataset_test_preds_weighted_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbbc4c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating stacking ensemble...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 72 features, but RidgeClassifierCV is expecting 90 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating stacking ensemble...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m stacked_features_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack([\n\u001b[0;32m      4\u001b[0m     logits_deberta_test_tta,\n\u001b[0;32m      5\u001b[0m     logits_distilbert_test,\n\u001b[0;32m      6\u001b[0m     logits_logreg_test,\n\u001b[0;32m      7\u001b[0m     logits_xgb_test\n\u001b[0;32m      8\u001b[0m ])\n\u001b[1;32m---> 10\u001b[0m pred_stacking_test \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacked_features_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m pred_labels_stacking \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([mlb\u001b[38;5;241m.\u001b[39mclasses_[j] \u001b[38;5;28;01mfor\u001b[39;00m j, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row) \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m pred_stacking_test]\n\u001b[0;32m     13\u001b[0m result_stacking \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovie_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovie_name\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m\"\u001b[39m: pred_labels_stacking,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     17\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\NV\\lib\\site-packages\\sklearn\\multiclass.py:512\u001b[0m, in \u001b[0;36mOneVsRestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    510\u001b[0m indptr \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_:\n\u001b[1;32m--> 512\u001b[0m     indices\u001b[38;5;241m.\u001b[39mextend(np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43m_predict_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m thresh)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    513\u001b[0m     indptr\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(indices))\n\u001b[0;32m    514\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\NV\\lib\\site-packages\\sklearn\\multiclass.py:111\u001b[0m, in \u001b[0;36m_predict_binary\u001b[1;34m(estimator, X)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m     score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# probabilities of the positive class\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     score \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\NV\\lib\\site-packages\\sklearn\\linear_model\\_base.py:352\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    349\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 352\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    355\u001b[0m     xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (scores\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[0;32m    358\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\NV\\lib\\site-packages\\sklearn\\utils\\validation.py:2975\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2972\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2975\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\NV\\lib\\site-packages\\sklearn\\utils\\validation.py:2839\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2841\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2842\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 72 features, but RidgeClassifierCV is expecting 90 features as input."
     ]
    }
   ],
   "source": [
    "# Crear stacking ensemble\n",
    "print(\"Creating stacking ensemble...\")\n",
    "stacked_features_test = np.column_stack([\n",
    "    logits_deberta_test_tta,\n",
    "    logits_distilbert_test,\n",
    "    logits_logreg_test,\n",
    "    logits_xgb_test\n",
    "])\n",
    "\n",
    "pred_stacking_test = meta_model.predict(stacked_features_test)\n",
    "\n",
    "pred_labels_stacking = [\", \".join([mlb.classes_[j] for j, v in enumerate(row) if v == 1]) for row in pred_stacking_test]\n",
    "result_stacking = pd.DataFrame({\n",
    "    \"movie_name\": df_test[\"movie_name\"],\n",
    "    \"genre\": pred_labels_stacking,\n",
    "    \"description\": df_test[\"description\"]\n",
    "})\n",
    "result_stacking.to_csv(\"dataset_test_preds_stacking_ensemble.csv\", index=False)\n",
    "print(f\"✓ Stacking Ensemble predictions saved: dataset_test_preds_stacking_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a10082f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SELECTING BEST ENSEMBLE FOR FINAL SUBMISSION\n",
      "================================================================================\n",
      "Stacking Ensemble Validation F1: 0.6637 (may be optimistic)\n",
      "Weighted Ensemble Validation F1: 0.6519 (more reliable)\n",
      "================================================================================\n",
      "\n",
      "✓ USING WEIGHTED ENSEMBLE (F1=0.6519) for final submission\n",
      "  Reason: Optimized with Optuna on clean validation set, no data leakage\n",
      "\n",
      "✓✓✓ FINAL SUBMISSION saved: dataset_test_preds.csv ✓✓✓\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar ensemble final para submission\n",
    "print(\"=\"*80)\n",
    "print(\"SELECTING BEST ENSEMBLE FOR FINAL SUBMISSION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Stacking Ensemble Validation F1: {metrics_stacking['f1']:.4f} (may be optimistic)\")\n",
    "print(f\"Weighted Ensemble Validation F1: {metrics_optimized['f1']:.4f} (more reliable)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# USAR SIEMPRE WEIGHTED ENSEMBLE (más confiable, sin data leakage)\n",
    "print(f\"\\n✓ USING WEIGHTED ENSEMBLE (F1={metrics_optimized['f1']:.4f}) for final submission\")\n",
    "print(\"  Reason: Optimized with Optuna on clean validation set, no data leakage\")\n",
    "final_submission = result_optimized.copy()\n",
    "final_submission.to_csv(\"dataset_test_preds.csv\", index=False)\n",
    "\n",
    "print(f\"\\n✓✓✓ FINAL SUBMISSION saved: dataset_test_preds.csv ✓✓✓\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e1a38",
   "metadata": {},
   "source": [
    "## 14. Resumen Final de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd2a296c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VALIDATION PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "1. LogReg (TF-IDF+BGE):         F1: 0.6345, Hamming: 0.1021\n",
      "2. XGBoost (BGE Embeddings):    F1: 0.6224, Hamming: 0.1046\n",
      "3. LinearSVC (TF-IDF):          F1: 0.5655, Hamming: 0.1238\n",
      "4. Calibrated SVC:              F1: 0.5739, Hamming: 0.1203\n",
      "5. DistilBERT (Focal+Smooth):   F1: 0.6508, Hamming: 0.0927\n",
      "6. DeBERTa-v3 (Focal+Smooth):   F1: 0.6385, Hamming: 0.0993\n",
      "7. STACKING Ensemble:           F1: 0.6637, Hamming: 0.0710 ⚠️\n",
      "8. WEIGHTED Ensemble (Optuna):  F1: 0.6519, Hamming: 0.0903 ✓\n",
      "================================================================================\n",
      "\n",
      "✓ Data Augmentation: 35% of train only (validation untouched)\n",
      "✓ TF-IDF: n-grams (1,4) word + (3,6) char, max_features=750k\n",
      "✓ Embeddings: BGE-Large-en-v1.5 (1024 dim, normalized)\n",
      "✓ Loss: Focal Loss (alpha=0.25, gamma=2.0) + Label Smoothing (0.1)\n",
      "✓ Calibration: SVC with sigmoid on train (cv=3)\n",
      "✓ Ensemble: Weighted optimized with Optuna (F1 - 0.3*Hamming, 50 trials)\n",
      "✓ Metrics: All calculated with validator.py compute_metrics()\n",
      "\n",
      "⚠️  Stacking trained on validation (may overfit) - Weighted Ensemble preferred\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"VALIDATION PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"1. LogReg (TF-IDF+BGE):         F1: {metrics_logreg['f1']:.4f}, Hamming: {metrics_logreg['hamming_loss']:.4f}\")\n",
    "print(f\"2. XGBoost (BGE Embeddings):    F1: {metrics_xgb['f1']:.4f}, Hamming: {metrics_xgb['hamming_loss']:.4f}\")\n",
    "print(f\"3. LinearSVC (TF-IDF):          F1: {metrics_svc['f1']:.4f}, Hamming: {metrics_svc['hamming_loss']:.4f}\")\n",
    "print(f\"4. Calibrated SVC:              F1: {metrics_svc_cal['f1']:.4f}, Hamming: {metrics_svc_cal['hamming_loss']:.4f}\")\n",
    "print(f\"5. DistilBERT (Focal+Smooth):   F1: {metrics_distilbert['f1']:.4f}, Hamming: {metrics_distilbert['hamming_loss']:.4f}\")\n",
    "print(f\"6. DeBERTa-v3 (Focal+Smooth):   F1: {metrics_deberta['f1']:.4f}, Hamming: {metrics_deberta['hamming_loss']:.4f}\")\n",
    "print(f\"7. STACKING Ensemble:           F1: {metrics_stacking['f1']:.4f}, Hamming: {metrics_stacking['hamming_loss']:.4f} ⚠️\")\n",
    "print(f\"8. WEIGHTED Ensemble (Optuna):  F1: {metrics_optimized['f1']:.4f}, Hamming: {metrics_optimized['hamming_loss']:.4f} ✓\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n✓ Data Augmentation: 35% of train only (validation untouched)\")\n",
    "print(f\"✓ TF-IDF: n-grams (1,4) word + (3,6) char, max_features=750k\")\n",
    "print(f\"✓ Embeddings: BGE-Large-en-v1.5 (1024 dim, normalized)\")\n",
    "print(f\"✓ Loss: Focal Loss (alpha=0.25, gamma=2.0) + Label Smoothing (0.1)\")\n",
    "print(f\"✓ Calibration: SVC with sigmoid on train (cv=3)\")\n",
    "print(f\"✓ Ensemble: Weighted optimized with Optuna (F1 - 0.3*Hamming, 50 trials)\")\n",
    "print(f\"✓ Metrics: All calculated with validator.py compute_metrics()\")\n",
    "print(f\"\\n⚠️  Stacking trained on validation (may overfit) - Weighted Ensemble preferred\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14bc8fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ARCHIVOS CSV GENERADOS PARA CADA MODELO:\n",
      "================================================================================\n",
      "1. dataset_test_preds_logreg.csv\n",
      "2. dataset_test_preds_xgb.csv\n",
      "3. dataset_test_preds_svc.csv\n",
      "4. dataset_test_preds_svc_calibrated.csv\n",
      "5. dataset_test_preds_distilbert.csv\n",
      "6. dataset_test_preds_deberta.csv\n",
      "7. dataset_test_preds_weighted_ensemble.csv\n",
      "8. dataset_test_preds_stacking_ensemble.csv\n",
      "9. dataset_test_preds.csv (MEJOR ENSEMBLE - ENVIAR ESTE)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARCHIVOS CSV GENERADOS PARA CADA MODELO:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. dataset_test_preds_logreg.csv\")\n",
    "print(\"2. dataset_test_preds_xgb.csv\")\n",
    "print(\"3. dataset_test_preds_svc.csv\")\n",
    "print(\"4. dataset_test_preds_svc_calibrated.csv\")\n",
    "print(\"5. dataset_test_preds_distilbert.csv\")\n",
    "print(\"6. dataset_test_preds_deberta.csv\")\n",
    "print(\"7. dataset_test_preds_weighted_ensemble.csv\")\n",
    "print(\"8. dataset_test_preds_stacking_ensemble.csv\")\n",
    "print(\"9. dataset_test_preds.csv (MEJOR ENSEMBLE - ENVIAR ESTE)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74138a24",
   "metadata": {},
   "source": [
    "## 📝 CÓMO SE GENERA EL ARCHIVO FINAL\n",
    "\n",
    "El archivo **`dataset_test_preds.csv`** se genera así:\n",
    "\n",
    "1. **Se entrenan 6 modelos** en el dataset de train:\n",
    "   - LogisticRegression, XGBoost, LinearSVC, Calibrated SVC, DistilBERT, DeBERTa\n",
    "\n",
    "2. **Cada modelo genera predicciones en test** → 6 archivos CSV individuales\n",
    "\n",
    "3. **Se crean 2 ensembles**:\n",
    "   - **Weighted Ensemble**: Combina los 6 modelos con pesos optimizados por Optuna\n",
    "   - **Stacking Ensemble**: Usa un meta-modelo Ridge para combinar predicciones\n",
    "\n",
    "4. **Se selecciona el mejor ensemble** basado en F1 score de validación:\n",
    "   - Si `metrics_stacking['f1'] > metrics_optimized['f1']` → usa Stacking\n",
    "   - Si no → usa Weighted Ensemble (recomendado, más confiable)\n",
    "\n",
    "5. **El mejor ensemble se guarda como `dataset_test_preds.csv`** ← **ESTE ES EL ARCHIVO FINAL PARA ENVIAR**\n",
    "\n",
    "**Resumen de archivos CSV generados:**\n",
    "- 6 archivos individuales por modelo (para análisis)\n",
    "- 2 archivos de ensemble (weighted y stacking)\n",
    "- **1 archivo final: `dataset_test_preds.csv`** ✅ ← Enviar este"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
